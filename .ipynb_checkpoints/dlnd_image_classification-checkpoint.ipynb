{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16c6e694ef0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    #Optimize colors for black RGB 0 = 1 RGB 255 = 0\n",
    "    #RGB(0,0,0) = Black\n",
    "    #RGB(255,255,255) = White\n",
    "    \n",
    "    divisor = lambda n: (255 - n) / 255\n",
    "    return np.array([divisor(xi) for xi in x])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    #Create vectors representing the numbers 0 -> 9 using one hot encoding\n",
    "    label_size = 10\n",
    "    ishot = lambda x, y: 1 if x == y else 0\n",
    "    ishot_vector = lambda l: np.array([ishot(l, i) for i in range(label_size)])\n",
    "\n",
    "    return np.array([ishot_vector(xi) for xi in x])\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, \n",
    "                            shape=[None, image_shape[0], image_shape[1], image_shape[2]], \n",
    "                            name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, \n",
    "                            shape=[None, n_classes], \n",
    "                            name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,\n",
    "                            shape=None,\n",
    "                            name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_var(shape):\n",
    "    #Initialize Weight Variable, with stddev to prevent dead neurons\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "def bias_var(num_outputs):\n",
    "    #Initalize Bias Variable with 0.1 to prevent dead neurons\n",
    "    return tf.Variable(tf.constant(0.05, shape=tf.TensorShape(num_outputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    #Get Tensor Shape\n",
    "    x_tensor_shape = x_tensor.get_shape().as_list()\n",
    "    #Generate Weight based off of ksize, tensor depth, and conv_num_outputs\n",
    "    weight = weight_var((conv_ksize[0], conv_ksize[1], x_tensor_shape[3], conv_num_outputs))\n",
    "    #Generate Bias based off of conv_num_outputs\n",
    "    bias = bias_var(conv_num_outputs)\n",
    "    #Create Conv Layer From x_tensor, add Bias\n",
    "    conv_layer = tf.nn.conv2d(x_tensor, weight, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME') + bias\n",
    "    #Apply ReLU Activation Function\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    #Return Max Pooling\n",
    "    return tf.nn.max_pool(conv_layer,\n",
    "                            ksize=[1, pool_ksize[0], pool_ksize[1], 1],\n",
    "                            strides=[1, pool_strides[0], pool_strides[1], 1],\n",
    "                            padding='SAME')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    #Get Tensor Shape\n",
    "    shape = x_tensor.get_shape().as_list()\n",
    "    #Flatten\n",
    "    return tf.reshape(x_tensor, [-1,shape[1]*shape[2]*shape[3]])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    #Generate Weights\n",
    "    weights = weight_var((x_tensor.get_shape().as_list()[1], num_outputs))\n",
    "    #Generate Biases\n",
    "    biases = bias_var(num_outputs)\n",
    "    #Generate Fully Connected Layer, Matrix Multiply, Add, Activate using Relu\n",
    "    return tf.nn.relu(tf.matmul(x_tensor, weights) + biases)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    #Generate Weights\n",
    "    weights = weight_var((x_tensor.get_shape().as_list()[1], num_outputs))\n",
    "    #Generate Biases\n",
    "    biases = bias_var(num_outputs)\n",
    "    #Return output, matrix multiply add biases, no activation\n",
    "    return tf.matmul(x_tensor, weights) + biases\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    #Set Starting Values\n",
    "    conv_ksize = [5,5]\n",
    "    conv_strides = [1,1]\n",
    "    pool_ksize = [2,2]\n",
    "    pool_strides = [2,2]\n",
    "    num_outputs = 10\n",
    "    \n",
    "    #Generate First Convolutional Layer using 32 Size\n",
    "    conv1 = conv2d_maxpool(x, 32, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    #Generate Second Convolutional Layer using 64 Size\n",
    "    conv2 = conv2d_maxpool(conv1, 64, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    #Generate Third Convolutional Layer using 128 Size\n",
    "    conv3 = conv2d_maxpool(conv2, 128, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    #Flatten, Prep for Fully Connected Layer\n",
    "    flat1 = flatten(conv2)\n",
    "    \n",
    "    #Generate Fully Connected Layer\n",
    "    fc1 = fully_conn(flat1, 1664)\n",
    "    \n",
    "    #Apply Dropout To Reduce Overfitting\n",
    "    do1 = tf.nn.dropout(fc1, keep_prob)\n",
    "    \n",
    "    #Return Output\n",
    "    return output(do1, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    with session.as_default() as sess:\n",
    "        #Run Optimizer\n",
    "        sess.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    #Print & Calculate Accuracy & Loss\n",
    "    print(\"Valid Acc:\", \n",
    "          accuracy.eval(feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.0}),\n",
    "          \"Step Acc:\", \n",
    "          accuracy.eval(feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0}),\n",
    "          \"Loss:\", \n",
    "          cost.eval(feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0}))\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 70\n",
    "batch_size = 1024\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Valid Acc: 0.1038 Step Acc: 0.107673 Loss: 2.25793\n",
      "Epoch  2, CIFAR-10 Batch 1:  Valid Acc: 0.2734 Step Acc: 0.268564 Loss: 2.09822\n",
      "Epoch  3, CIFAR-10 Batch 1:  Valid Acc: 0.3226 Step Acc: 0.34901 Loss: 1.93828\n",
      "Epoch  4, CIFAR-10 Batch 1:  Valid Acc: 0.3702 Step Acc: 0.378713 Loss: 1.79882\n",
      "Epoch  5, CIFAR-10 Batch 1:  Valid Acc: 0.3864 Step Acc: 0.418317 Loss: 1.69662\n",
      "Epoch  6, CIFAR-10 Batch 1:  Valid Acc: 0.3934 Step Acc: 0.404703 Loss: 1.64644\n",
      "Epoch  7, CIFAR-10 Batch 1:  Valid Acc: 0.4354 Step Acc: 0.449257 Loss: 1.5353\n",
      "Epoch  8, CIFAR-10 Batch 1:  Valid Acc: 0.4506 Step Acc: 0.488861 Loss: 1.46278\n",
      "Epoch  9, CIFAR-10 Batch 1:  Valid Acc: 0.4652 Step Acc: 0.518564 Loss: 1.41844\n",
      "Epoch 10, CIFAR-10 Batch 1:  Valid Acc: 0.4684 Step Acc: 0.533416 Loss: 1.36278\n",
      "Epoch 11, CIFAR-10 Batch 1:  Valid Acc: 0.4766 Step Acc: 0.539604 Loss: 1.33096\n",
      "Epoch 12, CIFAR-10 Batch 1:  Valid Acc: 0.4908 Step Acc: 0.556931 Loss: 1.27181\n",
      "Epoch 13, CIFAR-10 Batch 1:  Valid Acc: 0.4898 Step Acc: 0.564356 Loss: 1.21954\n",
      "Epoch 14, CIFAR-10 Batch 1:  Valid Acc: 0.4946 Step Acc: 0.596535 Loss: 1.17196\n",
      "Epoch 15, CIFAR-10 Batch 1:  Valid Acc: 0.503 Step Acc: 0.600248 Loss: 1.13979\n",
      "Epoch 16, CIFAR-10 Batch 1:  Valid Acc: 0.5094 Step Acc: 0.637376 Loss: 1.07998\n",
      "Epoch 17, CIFAR-10 Batch 1:  Valid Acc: 0.5108 Step Acc: 0.649752 Loss: 1.03908\n",
      "Epoch 18, CIFAR-10 Batch 1:  Valid Acc: 0.5158 Step Acc: 0.668317 Loss: 1.003\n",
      "Epoch 19, CIFAR-10 Batch 1:  Valid Acc: 0.5268 Step Acc: 0.694307 Loss: 0.955426\n",
      "Epoch 20, CIFAR-10 Batch 1:  Valid Acc: 0.536 Step Acc: 0.722772 Loss: 0.880637\n",
      "Epoch 21, CIFAR-10 Batch 1:  Valid Acc: 0.537 Step Acc: 0.743812 Loss: 0.839123\n",
      "Epoch 22, CIFAR-10 Batch 1:  Valid Acc: 0.5368 Step Acc: 0.743812 Loss: 0.808393\n",
      "Epoch 23, CIFAR-10 Batch 1:  Valid Acc: 0.549 Step Acc: 0.756188 Loss: 0.769088\n",
      "Epoch 24, CIFAR-10 Batch 1:  Valid Acc: 0.5474 Step Acc: 0.787129 Loss: 0.711068\n",
      "Epoch 25, CIFAR-10 Batch 1:  Valid Acc: 0.551 Step Acc: 0.787129 Loss: 0.68422\n",
      "Epoch 26, CIFAR-10 Batch 1:  Valid Acc: 0.554 Step Acc: 0.818069 Loss: 0.632783\n",
      "Epoch 27, CIFAR-10 Batch 1:  Valid Acc: 0.5582 Step Acc: 0.841584 Loss: 0.581395\n",
      "Epoch 28, CIFAR-10 Batch 1:  Valid Acc: 0.558 Step Acc: 0.852723 Loss: 0.554641\n",
      "Epoch 29, CIFAR-10 Batch 1:  Valid Acc: 0.5544 Step Acc: 0.860148 Loss: 0.524461\n",
      "Epoch 30, CIFAR-10 Batch 1:  Valid Acc: 0.554 Step Acc: 0.876238 Loss: 0.490075\n",
      "Epoch 31, CIFAR-10 Batch 1:  Valid Acc: 0.5596 Step Acc: 0.881188 Loss: 0.446047\n",
      "Epoch 32, CIFAR-10 Batch 1:  Valid Acc: 0.5554 Step Acc: 0.89604 Loss: 0.426101\n",
      "Epoch 33, CIFAR-10 Batch 1:  Valid Acc: 0.55 Step Acc: 0.904703 Loss: 0.396977\n",
      "Epoch 34, CIFAR-10 Batch 1:  Valid Acc: 0.5138 Step Acc: 0.872525 Loss: 0.463871\n",
      "Epoch 35, CIFAR-10 Batch 1:  Valid Acc: 0.537 Step Acc: 0.877475 Loss: 0.439581\n",
      "Epoch 36, CIFAR-10 Batch 1:  Valid Acc: 0.549 Step Acc: 0.905941 Loss: 0.369245\n",
      "Epoch 37, CIFAR-10 Batch 1:  Valid Acc: 0.5376 Step Acc: 0.89604 Loss: 0.390717\n",
      "Epoch 38, CIFAR-10 Batch 1:  Valid Acc: 0.5396 Step Acc: 0.914604 Loss: 0.331618\n",
      "Epoch 39, CIFAR-10 Batch 1:  Valid Acc: 0.5446 Step Acc: 0.928218 Loss: 0.302119\n",
      "Epoch 40, CIFAR-10 Batch 1:  Valid Acc: 0.5542 Step Acc: 0.946782 Loss: 0.256953\n",
      "Epoch 41, CIFAR-10 Batch 1:  Valid Acc: 0.5416 Step Acc: 0.935644 Loss: 0.272608\n",
      "Epoch 42, CIFAR-10 Batch 1:  Valid Acc: 0.5636 Step Acc: 0.955446 Loss: 0.227228\n",
      "Epoch 43, CIFAR-10 Batch 1:  Valid Acc: 0.5612 Step Acc: 0.959158 Loss: 0.201024\n",
      "Epoch 44, CIFAR-10 Batch 1:  Valid Acc: 0.5556 Step Acc: 0.956683 Loss: 0.207536\n",
      "Epoch 45, CIFAR-10 Batch 1:  Valid Acc: 0.5562 Step Acc: 0.962871 Loss: 0.170361\n",
      "Epoch 46, CIFAR-10 Batch 1:  Valid Acc: 0.5432 Step Acc: 0.970297 Loss: 0.170452\n",
      "Epoch 47, CIFAR-10 Batch 1:  Valid Acc: 0.556 Step Acc: 0.970297 Loss: 0.155248\n",
      "Epoch 48, CIFAR-10 Batch 1:  Valid Acc: 0.5562 Step Acc: 0.977723 Loss: 0.15263\n",
      "Epoch 49, CIFAR-10 Batch 1:  Valid Acc: 0.5604 Step Acc: 0.976485 Loss: 0.136364\n",
      "Epoch 50, CIFAR-10 Batch 1:  Valid Acc: 0.5516 Step Acc: 0.975248 Loss: 0.140765\n",
      "Epoch 51, CIFAR-10 Batch 1:  Valid Acc: 0.554 Step Acc: 0.97401 Loss: 0.122423\n",
      "Epoch 52, CIFAR-10 Batch 1:  Valid Acc: 0.559 Step Acc: 0.982673 Loss: 0.10427\n",
      "Epoch 53, CIFAR-10 Batch 1:  Valid Acc: 0.5502 Step Acc: 0.982673 Loss: 0.0960497\n",
      "Epoch 54, CIFAR-10 Batch 1:  Valid Acc: 0.5372 Step Acc: 0.970297 Loss: 0.106829\n",
      "Epoch 55, CIFAR-10 Batch 1:  Valid Acc: 0.5542 Step Acc: 0.991337 Loss: 0.0864793\n",
      "Epoch 56, CIFAR-10 Batch 1:  Valid Acc: 0.554 Step Acc: 0.986386 Loss: 0.0914696\n",
      "Epoch 57, CIFAR-10 Batch 1:  Valid Acc: 0.5614 Step Acc: 0.990099 Loss: 0.0770757\n",
      "Epoch 58, CIFAR-10 Batch 1:  Valid Acc: 0.55 Step Acc: 0.992574 Loss: 0.0731889\n",
      "Epoch 59, CIFAR-10 Batch 1:  Valid Acc: 0.5428 Step Acc: 0.988861 Loss: 0.0797363\n",
      "Epoch 60, CIFAR-10 Batch 1:  Valid Acc: 0.55 Step Acc: 0.991337 Loss: 0.062836\n",
      "Epoch 61, CIFAR-10 Batch 1:  Valid Acc: 0.5514 Step Acc: 0.992574 Loss: 0.0706797\n",
      "Epoch 62, CIFAR-10 Batch 1:  Valid Acc: 0.5648 Step Acc: 0.990099 Loss: 0.0663232\n",
      "Epoch 63, CIFAR-10 Batch 1:  Valid Acc: 0.558 Step Acc: 0.996287 Loss: 0.0579966\n",
      "Epoch 64, CIFAR-10 Batch 1:  Valid Acc: 0.5572 Step Acc: 0.995049 Loss: 0.0468322\n",
      "Epoch 65, CIFAR-10 Batch 1:  Valid Acc: 0.5628 Step Acc: 0.997525 Loss: 0.0370415\n",
      "Epoch 66, CIFAR-10 Batch 1:  Valid Acc: 0.565 Step Acc: 0.997525 Loss: 0.0337409\n",
      "Epoch 67, CIFAR-10 Batch 1:  Valid Acc: 0.552 Step Acc: 0.992574 Loss: 0.0409779\n",
      "Epoch 68, CIFAR-10 Batch 1:  Valid Acc: 0.5532 Step Acc: 0.996287 Loss: 0.038219\n",
      "Epoch 69, CIFAR-10 Batch 1:  Valid Acc: 0.5614 Step Acc: 0.996287 Loss: 0.0278487\n",
      "Epoch 70, CIFAR-10 Batch 1:  Valid Acc: 0.5674 Step Acc: 0.997525 Loss: 0.0236284\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Valid Acc: 0.1442 Step Acc: 0.136139 Loss: 2.25725\n",
      "Epoch  1, CIFAR-10 Batch 2:  Valid Acc: 0.2982 Step Acc: 0.280941 Loss: 2.04959\n",
      "Epoch  1, CIFAR-10 Batch 3:  Valid Acc: 0.3386 Step Acc: 0.351485 Loss: 1.83452\n",
      "Epoch  1, CIFAR-10 Batch 4:  Valid Acc: 0.3722 Step Acc: 0.366337 Loss: 1.77026\n",
      "Epoch  1, CIFAR-10 Batch 5:  Valid Acc: 0.4156 Step Acc: 0.417079 Loss: 1.66132\n",
      "Epoch  2, CIFAR-10 Batch 1:  Valid Acc: 0.4438 Step Acc: 0.417079 Loss: 1.63026\n",
      "Epoch  2, CIFAR-10 Batch 2:  Valid Acc: 0.4528 Step Acc: 0.451733 Loss: 1.56077\n",
      "Epoch  2, CIFAR-10 Batch 3:  Valid Acc: 0.4692 Step Acc: 0.502475 Loss: 1.43544\n",
      "Epoch  2, CIFAR-10 Batch 4:  Valid Acc: 0.499 Step Acc: 0.522277 Loss: 1.39028\n",
      "Epoch  2, CIFAR-10 Batch 5:  Valid Acc: 0.5002 Step Acc: 0.533416 Loss: 1.37881\n",
      "Epoch  3, CIFAR-10 Batch 1:  Valid Acc: 0.5078 Step Acc: 0.522277 Loss: 1.37437\n",
      "Epoch  3, CIFAR-10 Batch 2:  Valid Acc: 0.5306 Step Acc: 0.530941 Loss: 1.3375\n",
      "Epoch  3, CIFAR-10 Batch 3:  Valid Acc: 0.5146 Step Acc: 0.558168 Loss: 1.2508\n",
      "Epoch  3, CIFAR-10 Batch 4:  Valid Acc: 0.5292 Step Acc: 0.570545 Loss: 1.26644\n",
      "Epoch  3, CIFAR-10 Batch 5:  Valid Acc: 0.5372 Step Acc: 0.576733 Loss: 1.23286\n",
      "Epoch  4, CIFAR-10 Batch 1:  Valid Acc: 0.543 Step Acc: 0.569307 Loss: 1.24431\n",
      "Epoch  4, CIFAR-10 Batch 2:  Valid Acc: 0.5586 Step Acc: 0.563119 Loss: 1.2311\n",
      "Epoch  4, CIFAR-10 Batch 3:  Valid Acc: 0.556 Step Acc: 0.594059 Loss: 1.12981\n",
      "Epoch  4, CIFAR-10 Batch 4:  Valid Acc: 0.5696 Step Acc: 0.607673 Loss: 1.15851\n",
      "Epoch  4, CIFAR-10 Batch 5:  Valid Acc: 0.5726 Step Acc: 0.620049 Loss: 1.12171\n",
      "Epoch  5, CIFAR-10 Batch 1:  Valid Acc: 0.5788 Step Acc: 0.605198 Loss: 1.13963\n",
      "Epoch  5, CIFAR-10 Batch 2:  Valid Acc: 0.5814 Step Acc: 0.606436 Loss: 1.1516\n",
      "Epoch  5, CIFAR-10 Batch 3:  Valid Acc: 0.566 Step Acc: 0.620049 Loss: 1.0834\n",
      "Epoch  5, CIFAR-10 Batch 4:  Valid Acc: 0.598 Step Acc: 0.652228 Loss: 1.05789\n",
      "Epoch  5, CIFAR-10 Batch 5:  Valid Acc: 0.5954 Step Acc: 0.639852 Loss: 1.04892\n",
      "Epoch  6, CIFAR-10 Batch 1:  Valid Acc: 0.6022 Step Acc: 0.652228 Loss: 1.05065\n",
      "Epoch  6, CIFAR-10 Batch 2:  Valid Acc: 0.5926 Step Acc: 0.626238 Loss: 1.1015\n",
      "Epoch  6, CIFAR-10 Batch 3:  Valid Acc: 0.597 Step Acc: 0.636139 Loss: 1.00173\n",
      "Epoch  6, CIFAR-10 Batch 4:  Valid Acc: 0.6084 Step Acc: 0.662129 Loss: 1.00568\n",
      "Epoch  6, CIFAR-10 Batch 5:  Valid Acc: 0.6108 Step Acc: 0.673267 Loss: 0.962505\n",
      "Epoch  7, CIFAR-10 Batch 1:  Valid Acc: 0.6052 Step Acc: 0.664604 Loss: 1.01261\n",
      "Epoch  7, CIFAR-10 Batch 2:  Valid Acc: 0.6238 Step Acc: 0.659653 Loss: 1.01702\n",
      "Epoch  7, CIFAR-10 Batch 3:  Valid Acc: 0.6314 Step Acc: 0.675743 Loss: 0.891857\n",
      "Epoch  7, CIFAR-10 Batch 4:  Valid Acc: 0.626 Step Acc: 0.69802 Loss: 0.915148\n",
      "Epoch  7, CIFAR-10 Batch 5:  Valid Acc: 0.6322 Step Acc: 0.705446 Loss: 0.890937\n",
      "Epoch  8, CIFAR-10 Batch 1:  Valid Acc: 0.6238 Step Acc: 0.684406 Loss: 0.934937\n",
      "Epoch  8, CIFAR-10 Batch 2:  Valid Acc: 0.635 Step Acc: 0.681931 Loss: 0.936538\n",
      "Epoch  8, CIFAR-10 Batch 3:  Valid Acc: 0.634 Step Acc: 0.70297 Loss: 0.840689\n",
      "Epoch  8, CIFAR-10 Batch 4:  Valid Acc: 0.6446 Step Acc: 0.715347 Loss: 0.850946\n",
      "Epoch  8, CIFAR-10 Batch 5:  Valid Acc: 0.648 Step Acc: 0.727723 Loss: 0.809908\n",
      "Epoch  9, CIFAR-10 Batch 1:  Valid Acc: 0.6392 Step Acc: 0.704208 Loss: 0.862764\n",
      "Epoch  9, CIFAR-10 Batch 2:  Valid Acc: 0.6464 Step Acc: 0.712871 Loss: 0.870776\n",
      "Epoch  9, CIFAR-10 Batch 3:  Valid Acc: 0.6422 Step Acc: 0.72401 Loss: 0.788597\n",
      "Epoch  9, CIFAR-10 Batch 4:  Valid Acc: 0.6546 Step Acc: 0.751238 Loss: 0.793915\n",
      "Epoch  9, CIFAR-10 Batch 5:  Valid Acc: 0.6532 Step Acc: 0.758663 Loss: 0.750226\n",
      "Epoch 10, CIFAR-10 Batch 1:  Valid Acc: 0.6552 Step Acc: 0.738861 Loss: 0.784843\n",
      "Epoch 10, CIFAR-10 Batch 2:  Valid Acc: 0.6454 Step Acc: 0.737624 Loss: 0.828603\n",
      "Epoch 10, CIFAR-10 Batch 3:  Valid Acc: 0.6524 Step Acc: 0.758663 Loss: 0.721736\n",
      "Epoch 10, CIFAR-10 Batch 4:  Valid Acc: 0.6636 Step Acc: 0.772277 Loss: 0.733548\n",
      "Epoch 10, CIFAR-10 Batch 5:  Valid Acc: 0.6546 Step Acc: 0.764852 Loss: 0.702931\n",
      "Epoch 11, CIFAR-10 Batch 1:  Valid Acc: 0.655 Step Acc: 0.754951 Loss: 0.741028\n",
      "Epoch 11, CIFAR-10 Batch 2:  Valid Acc: 0.6472 Step Acc: 0.746287 Loss: 0.775561\n",
      "Epoch 11, CIFAR-10 Batch 3:  Valid Acc: 0.6482 Step Acc: 0.754951 Loss: 0.707901\n",
      "Epoch 11, CIFAR-10 Batch 4:  Valid Acc: 0.654 Step Acc: 0.764852 Loss: 0.723197\n",
      "Epoch 11, CIFAR-10 Batch 5:  Valid Acc: 0.6622 Step Acc: 0.790842 Loss: 0.665407\n",
      "Epoch 12, CIFAR-10 Batch 1:  Valid Acc: 0.6632 Step Acc: 0.756188 Loss: 0.697455\n",
      "Epoch 12, CIFAR-10 Batch 2:  Valid Acc: 0.6614 Step Acc: 0.77104 Loss: 0.717599\n",
      "Epoch 12, CIFAR-10 Batch 3:  Valid Acc: 0.6576 Step Acc: 0.785891 Loss: 0.652439\n",
      "Epoch 12, CIFAR-10 Batch 4:  Valid Acc: 0.666 Step Acc: 0.80198 Loss: 0.642709\n",
      "Epoch 12, CIFAR-10 Batch 5:  Valid Acc: 0.6736 Step Acc: 0.808168 Loss: 0.605792\n",
      "Epoch 13, CIFAR-10 Batch 1:  Valid Acc: 0.6716 Step Acc: 0.778465 Loss: 0.643919\n",
      "Epoch 13, CIFAR-10 Batch 2:  Valid Acc: 0.6668 Step Acc: 0.787129 Loss: 0.656115\n",
      "Epoch 13, CIFAR-10 Batch 3:  Valid Acc: 0.6678 Step Acc: 0.800743 Loss: 0.58902\n",
      "Epoch 13, CIFAR-10 Batch 4:  Valid Acc: 0.6724 Step Acc: 0.821782 Loss: 0.590028\n",
      "Epoch 13, CIFAR-10 Batch 5:  Valid Acc: 0.6744 Step Acc: 0.816832 Loss: 0.562879\n",
      "Epoch 14, CIFAR-10 Batch 1:  Valid Acc: 0.675 Step Acc: 0.798267 Loss: 0.580671\n",
      "Epoch 14, CIFAR-10 Batch 2:  Valid Acc: 0.6734 Step Acc: 0.806931 Loss: 0.602108\n",
      "Epoch 14, CIFAR-10 Batch 3:  Valid Acc: 0.6718 Step Acc: 0.829208 Loss: 0.549418\n",
      "Epoch 14, CIFAR-10 Batch 4:  Valid Acc: 0.6618 Step Acc: 0.826733 Loss: 0.583784\n",
      "Epoch 14, CIFAR-10 Batch 5:  Valid Acc: 0.6752 Step Acc: 0.841584 Loss: 0.511786\n",
      "Epoch 15, CIFAR-10 Batch 1:  Valid Acc: 0.6732 Step Acc: 0.82797 Loss: 0.5383\n",
      "Epoch 15, CIFAR-10 Batch 2:  Valid Acc: 0.6898 Step Acc: 0.839109 Loss: 0.535358\n",
      "Epoch 15, CIFAR-10 Batch 3:  Valid Acc: 0.6766 Step Acc: 0.834158 Loss: 0.500094\n",
      "Epoch 15, CIFAR-10 Batch 4:  Valid Acc: 0.6762 Step Acc: 0.846535 Loss: 0.519465\n",
      "Epoch 15, CIFAR-10 Batch 5:  Valid Acc: 0.673 Step Acc: 0.850248 Loss: 0.486981\n",
      "Epoch 16, CIFAR-10 Batch 1:  Valid Acc: 0.6724 Step Acc: 0.847772 Loss: 0.506669\n",
      "Epoch 16, CIFAR-10 Batch 2:  Valid Acc: 0.6824 Step Acc: 0.834158 Loss: 0.520193\n",
      "Epoch 16, CIFAR-10 Batch 3:  Valid Acc: 0.6858 Step Acc: 0.865099 Loss: 0.437685\n",
      "Epoch 16, CIFAR-10 Batch 4:  Valid Acc: 0.6648 Step Acc: 0.865099 Loss: 0.488776\n",
      "Epoch 16, CIFAR-10 Batch 5:  Valid Acc: 0.6806 Step Acc: 0.867574 Loss: 0.438735\n",
      "Epoch 17, CIFAR-10 Batch 1:  Valid Acc: 0.6762 Step Acc: 0.857673 Loss: 0.457868\n",
      "Epoch 17, CIFAR-10 Batch 2:  Valid Acc: 0.6916 Step Acc: 0.862624 Loss: 0.478036\n",
      "Epoch 17, CIFAR-10 Batch 3:  Valid Acc: 0.6882 Step Acc: 0.871287 Loss: 0.403679\n",
      "Epoch 17, CIFAR-10 Batch 4:  Valid Acc: 0.6756 Step Acc: 0.881188 Loss: 0.4289\n",
      "Epoch 17, CIFAR-10 Batch 5:  Valid Acc: 0.6816 Step Acc: 0.891089 Loss: 0.400106\n",
      "Epoch 18, CIFAR-10 Batch 1:  Valid Acc: 0.6874 Step Acc: 0.873762 Loss: 0.408386\n",
      "Epoch 18, CIFAR-10 Batch 2:  Valid Acc: 0.6824 Step Acc: 0.865099 Loss: 0.435041\n",
      "Epoch 18, CIFAR-10 Batch 3:  Valid Acc: 0.7004 Step Acc: 0.888614 Loss: 0.363772\n",
      "Epoch 18, CIFAR-10 Batch 4:  Valid Acc: 0.689 Step Acc: 0.897277 Loss: 0.37228\n",
      "Epoch 18, CIFAR-10 Batch 5:  Valid Acc: 0.6916 Step Acc: 0.907178 Loss: 0.34745\n",
      "Epoch 19, CIFAR-10 Batch 1:  Valid Acc: 0.6958 Step Acc: 0.877475 Loss: 0.371945\n",
      "Epoch 19, CIFAR-10 Batch 2:  Valid Acc: 0.6858 Step Acc: 0.878713 Loss: 0.386068\n",
      "Epoch 19, CIFAR-10 Batch 3:  Valid Acc: 0.688 Step Acc: 0.89604 Loss: 0.354122\n",
      "Epoch 19, CIFAR-10 Batch 4:  Valid Acc: 0.6944 Step Acc: 0.92203 Loss: 0.321828\n",
      "Epoch 19, CIFAR-10 Batch 5:  Valid Acc: 0.6962 Step Acc: 0.915842 Loss: 0.314093\n",
      "Epoch 20, CIFAR-10 Batch 1:  Valid Acc: 0.6948 Step Acc: 0.905941 Loss: 0.313199\n",
      "Epoch 20, CIFAR-10 Batch 2:  Valid Acc: 0.6954 Step Acc: 0.897277 Loss: 0.345212\n",
      "Epoch 20, CIFAR-10 Batch 3:  Valid Acc: 0.691 Step Acc: 0.902228 Loss: 0.32516\n",
      "Epoch 20, CIFAR-10 Batch 4:  Valid Acc: 0.6808 Step Acc: 0.923267 Loss: 0.314933\n",
      "Epoch 20, CIFAR-10 Batch 5:  Valid Acc: 0.6908 Step Acc: 0.909653 Loss: 0.304915\n",
      "Epoch 21, CIFAR-10 Batch 1:  Valid Acc: 0.6842 Step Acc: 0.923267 Loss: 0.291036\n",
      "Epoch 21, CIFAR-10 Batch 2:  Valid Acc: 0.7008 Step Acc: 0.915842 Loss: 0.302437\n",
      "Epoch 21, CIFAR-10 Batch 3:  Valid Acc: 0.6932 Step Acc: 0.923267 Loss: 0.277389\n",
      "Epoch 21, CIFAR-10 Batch 4:  Valid Acc: 0.6788 Step Acc: 0.931931 Loss: 0.278904\n",
      "Epoch 21, CIFAR-10 Batch 5:  Valid Acc: 0.676 Step Acc: 0.917079 Loss: 0.277728\n",
      "Epoch 22, CIFAR-10 Batch 1:  Valid Acc: 0.6956 Step Acc: 0.934406 Loss: 0.262826\n",
      "Epoch 22, CIFAR-10 Batch 2:  Valid Acc: 0.6992 Step Acc: 0.930693 Loss: 0.262912\n",
      "Epoch 22, CIFAR-10 Batch 3:  Valid Acc: 0.7032 Step Acc: 0.941832 Loss: 0.237408\n",
      "Epoch 22, CIFAR-10 Batch 4:  Valid Acc: 0.6872 Step Acc: 0.949257 Loss: 0.244764\n",
      "Epoch 22, CIFAR-10 Batch 5:  Valid Acc: 0.6786 Step Acc: 0.940594 Loss: 0.235107\n",
      "Epoch 23, CIFAR-10 Batch 1:  Valid Acc: 0.6858 Step Acc: 0.938119 Loss: 0.239098\n",
      "Epoch 23, CIFAR-10 Batch 2:  Valid Acc: 0.693 Step Acc: 0.939356 Loss: 0.23227\n",
      "Epoch 23, CIFAR-10 Batch 3:  Valid Acc: 0.6932 Step Acc: 0.951733 Loss: 0.225703\n",
      "Epoch 23, CIFAR-10 Batch 4:  Valid Acc: 0.69 Step Acc: 0.94802 Loss: 0.225177\n",
      "Epoch 23, CIFAR-10 Batch 5:  Valid Acc: 0.6774 Step Acc: 0.954208 Loss: 0.211793\n",
      "Epoch 24, CIFAR-10 Batch 1:  Valid Acc: 0.672 Step Acc: 0.935644 Loss: 0.247672\n",
      "Epoch 24, CIFAR-10 Batch 2:  Valid Acc: 0.6864 Step Acc: 0.943069 Loss: 0.23052\n",
      "Epoch 24, CIFAR-10 Batch 3:  Valid Acc: 0.6994 Step Acc: 0.959158 Loss: 0.202819\n",
      "Epoch 24, CIFAR-10 Batch 4:  Valid Acc: 0.69 Step Acc: 0.954208 Loss: 0.216161\n",
      "Epoch 24, CIFAR-10 Batch 5:  Valid Acc: 0.688 Step Acc: 0.964109 Loss: 0.184708\n",
      "Epoch 25, CIFAR-10 Batch 1:  Valid Acc: 0.6852 Step Acc: 0.961634 Loss: 0.195073\n",
      "Epoch 25, CIFAR-10 Batch 2:  Valid Acc: 0.6858 Step Acc: 0.941832 Loss: 0.208169\n",
      "Epoch 25, CIFAR-10 Batch 3:  Valid Acc: 0.6926 Step Acc: 0.935644 Loss: 0.211706\n",
      "Epoch 25, CIFAR-10 Batch 4:  Valid Acc: 0.6758 Step Acc: 0.934406 Loss: 0.238677\n",
      "Epoch 25, CIFAR-10 Batch 5:  Valid Acc: 0.679 Step Acc: 0.956683 Loss: 0.206773\n",
      "Epoch 26, CIFAR-10 Batch 1:  Valid Acc: 0.6864 Step Acc: 0.955446 Loss: 0.195123\n",
      "Epoch 26, CIFAR-10 Batch 2:  Valid Acc: 0.6968 Step Acc: 0.957921 Loss: 0.175661\n",
      "Epoch 26, CIFAR-10 Batch 3:  Valid Acc: 0.6848 Step Acc: 0.945545 Loss: 0.185007\n",
      "Epoch 26, CIFAR-10 Batch 4:  Valid Acc: 0.6908 Step Acc: 0.965347 Loss: 0.18936\n",
      "Epoch 26, CIFAR-10 Batch 5:  Valid Acc: 0.6914 Step Acc: 0.970297 Loss: 0.171981\n",
      "Epoch 27, CIFAR-10 Batch 1:  Valid Acc: 0.6884 Step Acc: 0.954208 Loss: 0.166667\n",
      "Epoch 27, CIFAR-10 Batch 2:  Valid Acc: 0.6986 Step Acc: 0.962871 Loss: 0.156554\n",
      "Epoch 27, CIFAR-10 Batch 3:  Valid Acc: 0.6928 Step Acc: 0.964109 Loss: 0.16177\n",
      "Epoch 27, CIFAR-10 Batch 4:  Valid Acc: 0.6988 Step Acc: 0.965347 Loss: 0.155869\n",
      "Epoch 27, CIFAR-10 Batch 5:  Valid Acc: 0.7002 Step Acc: 0.980198 Loss: 0.12705\n",
      "Epoch 28, CIFAR-10 Batch 1:  Valid Acc: 0.6948 Step Acc: 0.969059 Loss: 0.1293\n",
      "Epoch 28, CIFAR-10 Batch 2:  Valid Acc: 0.6918 Step Acc: 0.97401 Loss: 0.138166\n",
      "Epoch 28, CIFAR-10 Batch 3:  Valid Acc: 0.699 Step Acc: 0.972772 Loss: 0.12872\n",
      "Epoch 28, CIFAR-10 Batch 4:  Valid Acc: 0.6972 Step Acc: 0.972772 Loss: 0.13819\n",
      "Epoch 28, CIFAR-10 Batch 5:  Valid Acc: 0.7064 Step Acc: 0.982673 Loss: 0.108555\n",
      "Epoch 29, CIFAR-10 Batch 1:  Valid Acc: 0.7078 Step Acc: 0.987624 Loss: 0.0991949\n",
      "Epoch 29, CIFAR-10 Batch 2:  Valid Acc: 0.7 Step Acc: 0.97896 Loss: 0.104404\n",
      "Epoch 29, CIFAR-10 Batch 3:  Valid Acc: 0.6902 Step Acc: 0.975248 Loss: 0.118403\n",
      "Epoch 29, CIFAR-10 Batch 4:  Valid Acc: 0.7068 Step Acc: 0.986386 Loss: 0.0962545\n",
      "Epoch 29, CIFAR-10 Batch 5:  Valid Acc: 0.701 Step Acc: 0.990099 Loss: 0.096983\n",
      "Epoch 30, CIFAR-10 Batch 1:  Valid Acc: 0.7046 Step Acc: 0.982673 Loss: 0.0967385\n",
      "Epoch 30, CIFAR-10 Batch 2:  Valid Acc: 0.7014 Step Acc: 0.991337 Loss: 0.088063\n",
      "Epoch 30, CIFAR-10 Batch 3:  Valid Acc: 0.6986 Step Acc: 0.982673 Loss: 0.0900682\n",
      "Epoch 30, CIFAR-10 Batch 4:  Valid Acc: 0.7042 Step Acc: 0.991337 Loss: 0.0791347\n",
      "Epoch 30, CIFAR-10 Batch 5:  Valid Acc: 0.7038 Step Acc: 0.991337 Loss: 0.0746383\n",
      "Epoch 31, CIFAR-10 Batch 1:  Valid Acc: 0.7136 Step Acc: 0.987624 Loss: 0.0725764\n",
      "Epoch 31, CIFAR-10 Batch 2:  Valid Acc: 0.699 Step Acc: 0.988861 Loss: 0.0801652\n",
      "Epoch 31, CIFAR-10 Batch 3:  Valid Acc: 0.6966 Step Acc: 0.985148 Loss: 0.089218\n",
      "Epoch 31, CIFAR-10 Batch 4:  Valid Acc: 0.703 Step Acc: 0.990099 Loss: 0.0787649\n",
      "Epoch 31, CIFAR-10 Batch 5:  Valid Acc: 0.6996 Step Acc: 0.990099 Loss: 0.0722852\n",
      "Epoch 32, CIFAR-10 Batch 1:  Valid Acc: 0.711 Step Acc: 0.993812 Loss: 0.0658537\n",
      "Epoch 32, CIFAR-10 Batch 2:  Valid Acc: 0.6964 Step Acc: 0.996287 Loss: 0.0702089\n",
      "Epoch 32, CIFAR-10 Batch 3:  Valid Acc: 0.7016 Step Acc: 0.985148 Loss: 0.0761108\n",
      "Epoch 32, CIFAR-10 Batch 4:  Valid Acc: 0.7058 Step Acc: 0.995049 Loss: 0.0619016\n",
      "Epoch 32, CIFAR-10 Batch 5:  Valid Acc: 0.7024 Step Acc: 0.992574 Loss: 0.055503\n",
      "Epoch 33, CIFAR-10 Batch 1:  Valid Acc: 0.7106 Step Acc: 0.996287 Loss: 0.0531191\n",
      "Epoch 33, CIFAR-10 Batch 2:  Valid Acc: 0.6944 Step Acc: 0.992574 Loss: 0.0624674\n",
      "Epoch 33, CIFAR-10 Batch 3:  Valid Acc: 0.6994 Step Acc: 0.985148 Loss: 0.0682825\n",
      "Epoch 33, CIFAR-10 Batch 4:  Valid Acc: 0.6972 Step Acc: 0.993812 Loss: 0.0557868\n",
      "Epoch 33, CIFAR-10 Batch 5:  Valid Acc: 0.707 Step Acc: 0.991337 Loss: 0.0542316\n",
      "Epoch 34, CIFAR-10 Batch 1:  Valid Acc: 0.7056 Step Acc: 0.995049 Loss: 0.045226\n",
      "Epoch 34, CIFAR-10 Batch 2:  Valid Acc: 0.6932 Step Acc: 0.991337 Loss: 0.054902\n",
      "Epoch 34, CIFAR-10 Batch 3:  Valid Acc: 0.6964 Step Acc: 0.988861 Loss: 0.0613863\n",
      "Epoch 34, CIFAR-10 Batch 4:  Valid Acc: 0.7088 Step Acc: 0.997525 Loss: 0.0448695\n",
      "Epoch 34, CIFAR-10 Batch 5:  Valid Acc: 0.7136 Step Acc: 0.997525 Loss: 0.0423894\n",
      "Epoch 35, CIFAR-10 Batch 1:  Valid Acc: 0.7058 Step Acc: 0.988861 Loss: 0.048522\n",
      "Epoch 35, CIFAR-10 Batch 2:  Valid Acc: 0.6974 Step Acc: 0.995049 Loss: 0.0450389\n",
      "Epoch 35, CIFAR-10 Batch 3:  Valid Acc: 0.7072 Step Acc: 0.995049 Loss: 0.048322\n",
      "Epoch 35, CIFAR-10 Batch 4:  Valid Acc: 0.7074 Step Acc: 0.997525 Loss: 0.0399489\n",
      "Epoch 35, CIFAR-10 Batch 5:  Valid Acc: 0.711 Step Acc: 0.998762 Loss: 0.0320152\n",
      "Epoch 36, CIFAR-10 Batch 1:  Valid Acc: 0.707 Step Acc: 0.996287 Loss: 0.0345955\n",
      "Epoch 36, CIFAR-10 Batch 2:  Valid Acc: 0.6942 Step Acc: 0.996287 Loss: 0.0454064\n",
      "Epoch 36, CIFAR-10 Batch 3:  Valid Acc: 0.6994 Step Acc: 0.995049 Loss: 0.0455732\n",
      "Epoch 36, CIFAR-10 Batch 4:  Valid Acc: 0.6964 Step Acc: 0.996287 Loss: 0.0427714\n",
      "Epoch 36, CIFAR-10 Batch 5:  Valid Acc: 0.7074 Step Acc: 1.0 Loss: 0.0314588\n",
      "Epoch 37, CIFAR-10 Batch 1:  Valid Acc: 0.7038 Step Acc: 0.996287 Loss: 0.0352175\n",
      "Epoch 37, CIFAR-10 Batch 2:  Valid Acc: 0.708 Step Acc: 0.997525 Loss: 0.035946\n",
      "Epoch 37, CIFAR-10 Batch 3:  Valid Acc: 0.7098 Step Acc: 0.995049 Loss: 0.0365987\n",
      "Epoch 37, CIFAR-10 Batch 4:  Valid Acc: 0.691 Step Acc: 0.997525 Loss: 0.0392873\n",
      "Epoch 37, CIFAR-10 Batch 5:  Valid Acc: 0.7016 Step Acc: 0.997525 Loss: 0.0340775\n",
      "Epoch 38, CIFAR-10 Batch 1:  Valid Acc: 0.7058 Step Acc: 0.998762 Loss: 0.0268831\n",
      "Epoch 38, CIFAR-10 Batch 2:  Valid Acc: 0.7046 Step Acc: 0.998762 Loss: 0.0343728\n",
      "Epoch 38, CIFAR-10 Batch 3:  Valid Acc: 0.7088 Step Acc: 0.998762 Loss: 0.0326684\n",
      "Epoch 38, CIFAR-10 Batch 4:  Valid Acc: 0.7054 Step Acc: 1.0 Loss: 0.0281146\n",
      "Epoch 38, CIFAR-10 Batch 5:  Valid Acc: 0.702 Step Acc: 0.998762 Loss: 0.0330136\n",
      "Epoch 39, CIFAR-10 Batch 1:  Valid Acc: 0.6998 Step Acc: 0.996287 Loss: 0.0332165\n",
      "Epoch 39, CIFAR-10 Batch 2:  Valid Acc: 0.6936 Step Acc: 0.996287 Loss: 0.0367997\n",
      "Epoch 39, CIFAR-10 Batch 3:  Valid Acc: 0.6982 Step Acc: 0.998762 Loss: 0.0379243\n",
      "Epoch 39, CIFAR-10 Batch 4:  Valid Acc: 0.709 Step Acc: 1.0 Loss: 0.0250792\n",
      "Epoch 39, CIFAR-10 Batch 5:  Valid Acc: 0.7038 Step Acc: 1.0 Loss: 0.0275031\n",
      "Epoch 40, CIFAR-10 Batch 1:  Valid Acc: 0.7044 Step Acc: 0.998762 Loss: 0.0226909\n",
      "Epoch 40, CIFAR-10 Batch 2:  Valid Acc: 0.7046 Step Acc: 0.997525 Loss: 0.0239022\n",
      "Epoch 40, CIFAR-10 Batch 3:  Valid Acc: 0.6942 Step Acc: 0.998762 Loss: 0.0294469\n",
      "Epoch 40, CIFAR-10 Batch 4:  Valid Acc: 0.706 Step Acc: 0.998762 Loss: 0.0206094\n",
      "Epoch 40, CIFAR-10 Batch 5:  Valid Acc: 0.708 Step Acc: 1.0 Loss: 0.0229725\n",
      "Epoch 41, CIFAR-10 Batch 1:  Valid Acc: 0.6996 Step Acc: 0.997525 Loss: 0.0219291\n",
      "Epoch 41, CIFAR-10 Batch 2:  Valid Acc: 0.7034 Step Acc: 0.998762 Loss: 0.0266823\n",
      "Epoch 41, CIFAR-10 Batch 3:  Valid Acc: 0.6964 Step Acc: 1.0 Loss: 0.0232023\n",
      "Epoch 41, CIFAR-10 Batch 4:  Valid Acc: 0.698 Step Acc: 0.998762 Loss: 0.020962\n",
      "Epoch 41, CIFAR-10 Batch 5:  Valid Acc: 0.6988 Step Acc: 1.0 Loss: 0.0204807\n",
      "Epoch 42, CIFAR-10 Batch 1:  Valid Acc: 0.7054 Step Acc: 1.0 Loss: 0.0147677\n",
      "Epoch 42, CIFAR-10 Batch 2:  Valid Acc: 0.7082 Step Acc: 0.998762 Loss: 0.0167855\n",
      "Epoch 42, CIFAR-10 Batch 3:  Valid Acc: 0.6968 Step Acc: 1.0 Loss: 0.0237603\n",
      "Epoch 42, CIFAR-10 Batch 4:  Valid Acc: 0.6958 Step Acc: 1.0 Loss: 0.020941\n",
      "Epoch 42, CIFAR-10 Batch 5:  Valid Acc: 0.6984 Step Acc: 1.0 Loss: 0.0185959\n",
      "Epoch 43, CIFAR-10 Batch 1:  Valid Acc: 0.7038 Step Acc: 1.0 Loss: 0.0152127\n",
      "Epoch 43, CIFAR-10 Batch 2:  Valid Acc: 0.7138 Step Acc: 1.0 Loss: 0.0140333\n",
      "Epoch 43, CIFAR-10 Batch 3:  Valid Acc: 0.7006 Step Acc: 1.0 Loss: 0.0153515\n",
      "Epoch 43, CIFAR-10 Batch 4:  Valid Acc: 0.7024 Step Acc: 0.998762 Loss: 0.0160852\n",
      "Epoch 43, CIFAR-10 Batch 5:  Valid Acc: 0.6988 Step Acc: 1.0 Loss: 0.0146528\n",
      "Epoch 44, CIFAR-10 Batch 1:  Valid Acc: 0.7156 Step Acc: 1.0 Loss: 0.00950334\n",
      "Epoch 44, CIFAR-10 Batch 2:  Valid Acc: 0.7102 Step Acc: 0.998762 Loss: 0.0109164\n",
      "Epoch 44, CIFAR-10 Batch 3:  Valid Acc: 0.704 Step Acc: 1.0 Loss: 0.0142867\n",
      "Epoch 44, CIFAR-10 Batch 4:  Valid Acc: 0.6954 Step Acc: 0.998762 Loss: 0.0173178\n",
      "Epoch 44, CIFAR-10 Batch 5:  Valid Acc: 0.6962 Step Acc: 0.996287 Loss: 0.0194318\n",
      "Epoch 45, CIFAR-10 Batch 1:  Valid Acc: 0.7068 Step Acc: 1.0 Loss: 0.01078\n",
      "Epoch 45, CIFAR-10 Batch 2:  Valid Acc: 0.7088 Step Acc: 0.998762 Loss: 0.0123609\n",
      "Epoch 45, CIFAR-10 Batch 3:  Valid Acc: 0.7094 Step Acc: 1.0 Loss: 0.0107389\n",
      "Epoch 45, CIFAR-10 Batch 4:  Valid Acc: 0.6944 Step Acc: 1.0 Loss: 0.0141366\n",
      "Epoch 45, CIFAR-10 Batch 5:  Valid Acc: 0.6974 Step Acc: 1.0 Loss: 0.0115263\n",
      "Epoch 46, CIFAR-10 Batch 1:  Valid Acc: 0.7028 Step Acc: 0.998762 Loss: 0.0127331\n",
      "Epoch 46, CIFAR-10 Batch 2:  Valid Acc: 0.711 Step Acc: 0.998762 Loss: 0.0124889\n",
      "Epoch 46, CIFAR-10 Batch 3:  Valid Acc: 0.6996 Step Acc: 1.0 Loss: 0.0113534\n",
      "Epoch 46, CIFAR-10 Batch 4:  Valid Acc: 0.7 Step Acc: 1.0 Loss: 0.00806101\n",
      "Epoch 46, CIFAR-10 Batch 5:  Valid Acc: 0.6958 Step Acc: 1.0 Loss: 0.0106219\n",
      "Epoch 47, CIFAR-10 Batch 1:  Valid Acc: 0.712 Step Acc: 1.0 Loss: 0.0102879\n",
      "Epoch 47, CIFAR-10 Batch 2:  Valid Acc: 0.707 Step Acc: 1.0 Loss: 0.00993171\n",
      "Epoch 47, CIFAR-10 Batch 3:  Valid Acc: 0.7128 Step Acc: 1.0 Loss: 0.0110177\n",
      "Epoch 47, CIFAR-10 Batch 4:  Valid Acc: 0.7088 Step Acc: 1.0 Loss: 0.00688973\n",
      "Epoch 47, CIFAR-10 Batch 5:  Valid Acc: 0.7092 Step Acc: 1.0 Loss: 0.00907216\n",
      "Epoch 48, CIFAR-10 Batch 1:  Valid Acc: 0.7034 Step Acc: 0.997525 Loss: 0.0130011\n",
      "Epoch 48, CIFAR-10 Batch 2:  Valid Acc: 0.7018 Step Acc: 1.0 Loss: 0.0118465\n",
      "Epoch 48, CIFAR-10 Batch 3:  Valid Acc: 0.7074 Step Acc: 1.0 Loss: 0.0115364\n",
      "Epoch 48, CIFAR-10 Batch 4:  Valid Acc: 0.714 Step Acc: 1.0 Loss: 0.00639636\n",
      "Epoch 48, CIFAR-10 Batch 5:  Valid Acc: 0.706 Step Acc: 1.0 Loss: 0.0093749\n",
      "Epoch 49, CIFAR-10 Batch 1:  Valid Acc: 0.6966 Step Acc: 0.998762 Loss: 0.0185961\n",
      "Epoch 49, CIFAR-10 Batch 2:  Valid Acc: 0.6996 Step Acc: 1.0 Loss: 0.0107848\n",
      "Epoch 49, CIFAR-10 Batch 3:  Valid Acc: 0.6976 Step Acc: 0.998762 Loss: 0.0117525\n",
      "Epoch 49, CIFAR-10 Batch 4:  Valid Acc: 0.6998 Step Acc: 1.0 Loss: 0.00889445\n",
      "Epoch 49, CIFAR-10 Batch 5:  Valid Acc: 0.7038 Step Acc: 0.998762 Loss: 0.0101171\n",
      "Epoch 50, CIFAR-10 Batch 1:  Valid Acc: 0.7014 Step Acc: 0.998762 Loss: 0.0106975\n",
      "Epoch 50, CIFAR-10 Batch 2:  Valid Acc: 0.704 Step Acc: 1.0 Loss: 0.00726111\n",
      "Epoch 50, CIFAR-10 Batch 3:  Valid Acc: 0.6992 Step Acc: 1.0 Loss: 0.00680495\n",
      "Epoch 50, CIFAR-10 Batch 4:  Valid Acc: 0.704 Step Acc: 1.0 Loss: 0.00603413\n",
      "Epoch 50, CIFAR-10 Batch 5:  Valid Acc: 0.7044 Step Acc: 0.998762 Loss: 0.0082306\n",
      "Epoch 51, CIFAR-10 Batch 1:  Valid Acc: 0.7068 Step Acc: 1.0 Loss: 0.00757026\n",
      "Epoch 51, CIFAR-10 Batch 2:  Valid Acc: 0.7068 Step Acc: 0.997525 Loss: 0.00859438\n",
      "Epoch 51, CIFAR-10 Batch 3:  Valid Acc: 0.7152 Step Acc: 1.0 Loss: 0.00588346\n",
      "Epoch 51, CIFAR-10 Batch 4:  Valid Acc: 0.713 Step Acc: 1.0 Loss: 0.00375826\n",
      "Epoch 51, CIFAR-10 Batch 5:  Valid Acc: 0.7066 Step Acc: 1.0 Loss: 0.00363941\n",
      "Epoch 52, CIFAR-10 Batch 1:  Valid Acc: 0.7038 Step Acc: 1.0 Loss: 0.00488568\n",
      "Epoch 52, CIFAR-10 Batch 2:  Valid Acc: 0.7104 Step Acc: 1.0 Loss: 0.00573059\n",
      "Epoch 52, CIFAR-10 Batch 3:  Valid Acc: 0.7126 Step Acc: 0.998762 Loss: 0.00690499\n",
      "Epoch 52, CIFAR-10 Batch 4:  Valid Acc: 0.7148 Step Acc: 1.0 Loss: 0.00339939\n",
      "Epoch 52, CIFAR-10 Batch 5:  Valid Acc: 0.7138 Step Acc: 1.0 Loss: 0.00365383\n",
      "Epoch 53, CIFAR-10 Batch 1:  Valid Acc: 0.7122 Step Acc: 1.0 Loss: 0.00430573\n",
      "Epoch 53, CIFAR-10 Batch 2:  Valid Acc: 0.713 Step Acc: 1.0 Loss: 0.00445148\n",
      "Epoch 53, CIFAR-10 Batch 3:  Valid Acc: 0.7112 Step Acc: 1.0 Loss: 0.00440879\n",
      "Epoch 53, CIFAR-10 Batch 4:  Valid Acc: 0.7106 Step Acc: 1.0 Loss: 0.00330369\n",
      "Epoch 53, CIFAR-10 Batch 5:  Valid Acc: 0.707 Step Acc: 0.998762 Loss: 0.00481921\n",
      "Epoch 54, CIFAR-10 Batch 1:  Valid Acc: 0.7046 Step Acc: 1.0 Loss: 0.00507982\n",
      "Epoch 54, CIFAR-10 Batch 2:  Valid Acc: 0.7098 Step Acc: 1.0 Loss: 0.00386426\n",
      "Epoch 54, CIFAR-10 Batch 3:  Valid Acc: 0.713 Step Acc: 1.0 Loss: 0.00465816\n",
      "Epoch 54, CIFAR-10 Batch 4:  Valid Acc: 0.7174 Step Acc: 1.0 Loss: 0.00337666\n",
      "Epoch 54, CIFAR-10 Batch 5:  Valid Acc: 0.7156 Step Acc: 1.0 Loss: 0.00251927\n",
      "Epoch 55, CIFAR-10 Batch 1:  Valid Acc: 0.7062 Step Acc: 1.0 Loss: 0.00465419\n",
      "Epoch 55, CIFAR-10 Batch 2:  Valid Acc: 0.7064 Step Acc: 0.998762 Loss: 0.0054557\n",
      "Epoch 55, CIFAR-10 Batch 3:  Valid Acc: 0.7026 Step Acc: 1.0 Loss: 0.00408664\n",
      "Epoch 55, CIFAR-10 Batch 4:  Valid Acc: 0.7168 Step Acc: 1.0 Loss: 0.00245552\n",
      "Epoch 55, CIFAR-10 Batch 5:  Valid Acc: 0.7084 Step Acc: 1.0 Loss: 0.00364624\n",
      "Epoch 56, CIFAR-10 Batch 1:  Valid Acc: 0.7146 Step Acc: 1.0 Loss: 0.00337\n",
      "Epoch 56, CIFAR-10 Batch 2:  Valid Acc: 0.7122 Step Acc: 1.0 Loss: 0.00378322\n",
      "Epoch 56, CIFAR-10 Batch 3:  Valid Acc: 0.7146 Step Acc: 1.0 Loss: 0.00368019\n",
      "Epoch 56, CIFAR-10 Batch 4:  Valid Acc: 0.7084 Step Acc: 1.0 Loss: 0.00417032\n",
      "Epoch 56, CIFAR-10 Batch 5:  Valid Acc: 0.7134 Step Acc: 1.0 Loss: 0.00284924\n",
      "Epoch 57, CIFAR-10 Batch 1:  Valid Acc: 0.7134 Step Acc: 1.0 Loss: 0.00233914\n",
      "Epoch 57, CIFAR-10 Batch 2:  Valid Acc: 0.7136 Step Acc: 1.0 Loss: 0.00489541\n",
      "Epoch 57, CIFAR-10 Batch 3:  Valid Acc: 0.7096 Step Acc: 1.0 Loss: 0.00346286\n",
      "Epoch 57, CIFAR-10 Batch 4:  Valid Acc: 0.7098 Step Acc: 1.0 Loss: 0.00200986\n",
      "Epoch 57, CIFAR-10 Batch 5:  Valid Acc: 0.7158 Step Acc: 1.0 Loss: 0.00243365\n",
      "Epoch 58, CIFAR-10 Batch 1:  Valid Acc: 0.7156 Step Acc: 1.0 Loss: 0.00241937\n",
      "Epoch 58, CIFAR-10 Batch 2:  Valid Acc: 0.7072 Step Acc: 1.0 Loss: 0.00460237\n",
      "Epoch 58, CIFAR-10 Batch 3:  Valid Acc: 0.7124 Step Acc: 1.0 Loss: 0.00286442\n",
      "Epoch 58, CIFAR-10 Batch 4:  Valid Acc: 0.7154 Step Acc: 1.0 Loss: 0.00214016\n",
      "Epoch 58, CIFAR-10 Batch 5:  Valid Acc: 0.716 Step Acc: 1.0 Loss: 0.00276871\n",
      "Epoch 59, CIFAR-10 Batch 1:  Valid Acc: 0.71 Step Acc: 1.0 Loss: 0.00317482\n",
      "Epoch 59, CIFAR-10 Batch 2:  Valid Acc: 0.7078 Step Acc: 1.0 Loss: 0.0027357\n",
      "Epoch 59, CIFAR-10 Batch 3:  Valid Acc: 0.7138 Step Acc: 1.0 Loss: 0.00267329\n",
      "Epoch 59, CIFAR-10 Batch 4:  Valid Acc: 0.7126 Step Acc: 1.0 Loss: 0.0017648\n",
      "Epoch 59, CIFAR-10 Batch 5:  Valid Acc: 0.712 Step Acc: 1.0 Loss: 0.00310449\n",
      "Epoch 60, CIFAR-10 Batch 1:  Valid Acc: 0.7056 Step Acc: 1.0 Loss: 0.00319396\n",
      "Epoch 60, CIFAR-10 Batch 2:  Valid Acc: 0.707 Step Acc: 1.0 Loss: 0.00270882\n",
      "Epoch 60, CIFAR-10 Batch 3:  Valid Acc: 0.7116 Step Acc: 1.0 Loss: 0.00300477\n",
      "Epoch 60, CIFAR-10 Batch 4:  Valid Acc: 0.7072 Step Acc: 1.0 Loss: 0.00275693\n",
      "Epoch 60, CIFAR-10 Batch 5:  Valid Acc: 0.7124 Step Acc: 1.0 Loss: 0.00332655\n",
      "Epoch 61, CIFAR-10 Batch 1:  Valid Acc: 0.7054 Step Acc: 1.0 Loss: 0.0026381\n",
      "Epoch 61, CIFAR-10 Batch 2:  Valid Acc: 0.707 Step Acc: 1.0 Loss: 0.0024428\n",
      "Epoch 61, CIFAR-10 Batch 3:  Valid Acc: 0.713 Step Acc: 0.998762 Loss: 0.0030285\n",
      "Epoch 61, CIFAR-10 Batch 4:  Valid Acc: 0.7026 Step Acc: 1.0 Loss: 0.00252978\n",
      "Epoch 61, CIFAR-10 Batch 5:  Valid Acc: 0.7124 Step Acc: 1.0 Loss: 0.00207105\n",
      "Epoch 62, CIFAR-10 Batch 1:  Valid Acc: 0.708 Step Acc: 1.0 Loss: 0.00184182\n",
      "Epoch 62, CIFAR-10 Batch 2:  Valid Acc: 0.705 Step Acc: 1.0 Loss: 0.00180667\n",
      "Epoch 62, CIFAR-10 Batch 3:  Valid Acc: 0.7074 Step Acc: 1.0 Loss: 0.00248\n",
      "Epoch 62, CIFAR-10 Batch 4:  Valid Acc: 0.7058 Step Acc: 1.0 Loss: 0.00214483\n",
      "Epoch 62, CIFAR-10 Batch 5:  Valid Acc: 0.711 Step Acc: 1.0 Loss: 0.00165515\n",
      "Epoch 63, CIFAR-10 Batch 1:  Valid Acc: 0.708 Step Acc: 1.0 Loss: 0.00201007\n",
      "Epoch 63, CIFAR-10 Batch 2:  Valid Acc: 0.7032 Step Acc: 1.0 Loss: 0.00155014\n",
      "Epoch 63, CIFAR-10 Batch 3:  Valid Acc: 0.7128 Step Acc: 1.0 Loss: 0.00174575\n",
      "Epoch 63, CIFAR-10 Batch 4:  Valid Acc: 0.709 Step Acc: 1.0 Loss: 0.00185629\n",
      "Epoch 63, CIFAR-10 Batch 5:  Valid Acc: 0.7178 Step Acc: 1.0 Loss: 0.00151441\n",
      "Epoch 64, CIFAR-10 Batch 1:  Valid Acc: 0.7058 Step Acc: 1.0 Loss: 0.00217948\n",
      "Epoch 64, CIFAR-10 Batch 2:  Valid Acc: 0.698 Step Acc: 1.0 Loss: 0.00230589\n",
      "Epoch 64, CIFAR-10 Batch 3:  Valid Acc: 0.7084 Step Acc: 1.0 Loss: 0.00216441\n",
      "Epoch 64, CIFAR-10 Batch 4:  Valid Acc: 0.7056 Step Acc: 1.0 Loss: 0.00146227\n",
      "Epoch 64, CIFAR-10 Batch 5:  Valid Acc: 0.711 Step Acc: 1.0 Loss: 0.00152945\n",
      "Epoch 65, CIFAR-10 Batch 1:  Valid Acc: 0.7036 Step Acc: 1.0 Loss: 0.00192124\n",
      "Epoch 65, CIFAR-10 Batch 2:  Valid Acc: 0.6968 Step Acc: 1.0 Loss: 0.00193776\n",
      "Epoch 65, CIFAR-10 Batch 3:  Valid Acc: 0.708 Step Acc: 1.0 Loss: 0.00203538\n",
      "Epoch 65, CIFAR-10 Batch 4:  Valid Acc: 0.7102 Step Acc: 1.0 Loss: 0.00170869\n",
      "Epoch 65, CIFAR-10 Batch 5:  Valid Acc: 0.7144 Step Acc: 1.0 Loss: 0.00140028\n",
      "Epoch 66, CIFAR-10 Batch 1:  Valid Acc: 0.7018 Step Acc: 1.0 Loss: 0.00240354\n",
      "Epoch 66, CIFAR-10 Batch 2:  Valid Acc: 0.7046 Step Acc: 1.0 Loss: 0.00177197\n",
      "Epoch 66, CIFAR-10 Batch 3:  Valid Acc: 0.7092 Step Acc: 1.0 Loss: 0.00220996\n",
      "Epoch 66, CIFAR-10 Batch 4:  Valid Acc: 0.708 Step Acc: 1.0 Loss: 0.00130665\n",
      "Epoch 66, CIFAR-10 Batch 5:  Valid Acc: 0.7048 Step Acc: 1.0 Loss: 0.00163757\n",
      "Epoch 67, CIFAR-10 Batch 1:  Valid Acc: 0.6956 Step Acc: 1.0 Loss: 0.00213048\n",
      "Epoch 67, CIFAR-10 Batch 2:  Valid Acc: 0.7044 Step Acc: 1.0 Loss: 0.00151755\n",
      "Epoch 67, CIFAR-10 Batch 3:  Valid Acc: 0.7082 Step Acc: 1.0 Loss: 0.0023046\n",
      "Epoch 67, CIFAR-10 Batch 4:  Valid Acc: 0.7092 Step Acc: 1.0 Loss: 0.000995906\n",
      "Epoch 67, CIFAR-10 Batch 5:  Valid Acc: 0.706 Step Acc: 1.0 Loss: 0.0019894\n",
      "Epoch 68, CIFAR-10 Batch 1:  Valid Acc: 0.7004 Step Acc: 1.0 Loss: 0.00236524\n",
      "Epoch 68, CIFAR-10 Batch 2:  Valid Acc: 0.7066 Step Acc: 1.0 Loss: 0.00160076\n",
      "Epoch 68, CIFAR-10 Batch 3:  Valid Acc: 0.7084 Step Acc: 1.0 Loss: 0.00278029\n",
      "Epoch 68, CIFAR-10 Batch 4:  Valid Acc: 0.6998 Step Acc: 1.0 Loss: 0.00124184\n",
      "Epoch 68, CIFAR-10 Batch 5:  Valid Acc: 0.7134 Step Acc: 1.0 Loss: 0.00187169\n",
      "Epoch 69, CIFAR-10 Batch 1:  Valid Acc: 0.7006 Step Acc: 1.0 Loss: 0.00153935\n",
      "Epoch 69, CIFAR-10 Batch 2:  Valid Acc: 0.7094 Step Acc: 1.0 Loss: 0.00131224\n",
      "Epoch 69, CIFAR-10 Batch 3:  Valid Acc: 0.7094 Step Acc: 1.0 Loss: 0.00189039\n",
      "Epoch 69, CIFAR-10 Batch 4:  Valid Acc: 0.7044 Step Acc: 1.0 Loss: 0.00150088\n",
      "Epoch 69, CIFAR-10 Batch 5:  Valid Acc: 0.7036 Step Acc: 1.0 Loss: 0.00263964\n",
      "Epoch 70, CIFAR-10 Batch 1:  Valid Acc: 0.6986 Step Acc: 1.0 Loss: 0.00190906\n",
      "Epoch 70, CIFAR-10 Batch 2:  Valid Acc: 0.7036 Step Acc: 1.0 Loss: 0.00195349\n",
      "Epoch 70, CIFAR-10 Batch 3:  Valid Acc: 0.703 Step Acc: 1.0 Loss: 0.00248836\n",
      "Epoch 70, CIFAR-10 Batch 4:  Valid Acc: 0.7046 Step Acc: 1.0 Loss: 0.00114053\n",
      "Epoch 70, CIFAR-10 Batch 5:  Valid Acc: 0.691 Step Acc: 1.0 Loss: 0.00308039\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.6947704076766967\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niESaHIuIiIiIRJoci4iIiIhE/w9KBM1Bi+M0PwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16c69d55898>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
