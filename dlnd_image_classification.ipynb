{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [02:40, 1.06MB/s]                                                                                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20d979205f8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    #Divide by 255\n",
    "    \n",
    "    divisor = lambda n: n/255\n",
    "    return np.array([divisor(xi) for xi in x])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    #Create vectors representing the numbers 0 -> 9 using one hot encoding\n",
    "    label_size = 10\n",
    "    ishot = lambda x, y: 1 if x == y else 0\n",
    "    ishot_vector = lambda l: np.array([ishot(l, i) for i in range(label_size)])\n",
    "\n",
    "    return np.array([ishot_vector(xi) for xi in x])\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, \n",
    "                            shape=[None, image_shape[0], image_shape[1], image_shape[2]], \n",
    "                            name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, \n",
    "                            shape=[None, n_classes], \n",
    "                            name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,\n",
    "                            shape=None,\n",
    "                            name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_var(shape):\n",
    "    #Initialize Weight Variable, with stddev to prevent dead neurons\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "def bias_var(num_outputs):\n",
    "    #Initalize Bias Variable with 0.1 to prevent dead neurons\n",
    "    return tf.Variable(tf.constant(0.05, shape=tf.TensorShape(num_outputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    #Get Tensor Shape\n",
    "    x_tensor_shape = x_tensor.get_shape().as_list()\n",
    "    #Generate Weight based off of ksize, tensor depth, and conv_num_outputs\n",
    "    weight = weight_var((conv_ksize[0], conv_ksize[1], x_tensor_shape[3], conv_num_outputs))\n",
    "    #Generate Bias based off of conv_num_outputs\n",
    "    bias = bias_var(conv_num_outputs)\n",
    "    #Create Conv Layer From x_tensor, add Bias\n",
    "    conv_layer = tf.nn.conv2d(x_tensor, weight, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME') + bias\n",
    "    #Apply ReLU Activation Function\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    #Return Max Pooling\n",
    "    return tf.nn.max_pool(conv_layer,\n",
    "                            ksize=[1, pool_ksize[0], pool_ksize[1], 1],\n",
    "                            strides=[1, pool_strides[0], pool_strides[1], 1],\n",
    "                            padding='SAME')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    #Get Tensor Shape\n",
    "    shape = x_tensor.get_shape().as_list()\n",
    "    #Flatten\n",
    "    return tf.reshape(x_tensor, [-1,shape[1]*shape[2]*shape[3]])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    #Generate Weights\n",
    "    weights = weight_var((x_tensor.get_shape().as_list()[1], num_outputs))\n",
    "    #Generate Biases\n",
    "    biases = bias_var(num_outputs)\n",
    "    #Generate Fully Connected Layer, Matrix Multiply, Add, Activate using Relu\n",
    "    return tf.nn.relu(tf.matmul(x_tensor, weights) + biases)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    #Generate Weights\n",
    "    weights = weight_var((x_tensor.get_shape().as_list()[1], num_outputs))\n",
    "    #Generate Biases\n",
    "    biases = bias_var(num_outputs)\n",
    "    #Return output, matrix multiply add biases, no activation\n",
    "    return tf.matmul(x_tensor, weights) + biases\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    #Set Starting Values\n",
    "    conv_ksize = [5,5]\n",
    "    conv_strides = [1,1]\n",
    "    pool_ksize = [2,2]\n",
    "    pool_strides = [2,2]\n",
    "    num_outputs = 10\n",
    "    \n",
    "    #Generate First Convolutional Layer using 32 Size\n",
    "    conv1 = conv2d_maxpool(x, 32, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    #Generate Second Convolutional Layer using 64 Size\n",
    "    conv2 = conv2d_maxpool(conv1, 64, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    #Generate Third Convolutional Layer using 128 Size\n",
    "    conv3 = conv2d_maxpool(conv2, 128, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    #Flatten, Prep for Fully Connected Layer\n",
    "    flat1 = flatten(conv2)\n",
    "    \n",
    "    #Generate Fully Connected Layer\n",
    "    fc1 = fully_conn(flat1, 1664)\n",
    "    \n",
    "    #Apply Dropout To Reduce Overfitting\n",
    "    do1 = tf.nn.dropout(fc1, keep_prob)\n",
    "    \n",
    "    #Return Output\n",
    "    return output(do1, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    with session.as_default() as sess:\n",
    "        #Run Optimizer\n",
    "        sess.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    #Print & Calculate Accuracy & Loss\n",
    "    print(\"Valid Acc:\", \n",
    "          accuracy.eval(feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.0}),\n",
    "          \"Step Acc:\", \n",
    "          accuracy.eval(feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0}),\n",
    "          \"Loss:\", \n",
    "          cost.eval(feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0}))\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 70\n",
    "batch_size = 1024\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Valid Acc: 0.101 Step Acc: 0.0891089 Loss: 2.28129\n",
      "Epoch  2, CIFAR-10 Batch 1:  Valid Acc: 0.2956 Step Acc: 0.300743 Loss: 2.06196\n",
      "Epoch  3, CIFAR-10 Batch 1:  Valid Acc: 0.3362 Step Acc: 0.337871 Loss: 1.88411\n",
      "Epoch  4, CIFAR-10 Batch 1:  Valid Acc: 0.3672 Step Acc: 0.376238 Loss: 1.75129\n",
      "Epoch  5, CIFAR-10 Batch 1:  Valid Acc: 0.4154 Step Acc: 0.413366 Loss: 1.65234\n",
      "Epoch  6, CIFAR-10 Batch 1:  Valid Acc: 0.422 Step Acc: 0.449257 Loss: 1.58594\n",
      "Epoch  7, CIFAR-10 Batch 1:  Valid Acc: 0.4328 Step Acc: 0.455446 Loss: 1.53924\n",
      "Epoch  8, CIFAR-10 Batch 1:  Valid Acc: 0.4666 Step Acc: 0.498762 Loss: 1.42744\n",
      "Epoch  9, CIFAR-10 Batch 1:  Valid Acc: 0.4746 Step Acc: 0.513614 Loss: 1.36687\n",
      "Epoch 10, CIFAR-10 Batch 1:  Valid Acc: 0.4926 Step Acc: 0.545792 Loss: 1.28959\n",
      "Epoch 11, CIFAR-10 Batch 1:  Valid Acc: 0.51 Step Acc: 0.591584 Loss: 1.21263\n",
      "Epoch 12, CIFAR-10 Batch 1:  Valid Acc: 0.5194 Step Acc: 0.618812 Loss: 1.15722\n",
      "Epoch 13, CIFAR-10 Batch 1:  Valid Acc: 0.5162 Step Acc: 0.628713 Loss: 1.11988\n",
      "Epoch 14, CIFAR-10 Batch 1:  Valid Acc: 0.5352 Step Acc: 0.627475 Loss: 1.07731\n",
      "Epoch 15, CIFAR-10 Batch 1:  Valid Acc: 0.5344 Step Acc: 0.65099 Loss: 1.03729\n",
      "Epoch 16, CIFAR-10 Batch 1:  Valid Acc: 0.5378 Step Acc: 0.662129 Loss: 0.982305\n",
      "Epoch 17, CIFAR-10 Batch 1:  Valid Acc: 0.5498 Step Acc: 0.696782 Loss: 0.926676\n",
      "Epoch 18, CIFAR-10 Batch 1:  Valid Acc: 0.5484 Step Acc: 0.69802 Loss: 0.922701\n",
      "Epoch 19, CIFAR-10 Batch 1:  Valid Acc: 0.5602 Step Acc: 0.735149 Loss: 0.841902\n",
      "Epoch 20, CIFAR-10 Batch 1:  Valid Acc: 0.5562 Step Acc: 0.746287 Loss: 0.809183\n",
      "Epoch 21, CIFAR-10 Batch 1:  Valid Acc: 0.5668 Step Acc: 0.759901 Loss: 0.763189\n",
      "Epoch 22, CIFAR-10 Batch 1:  Valid Acc: 0.57 Step Acc: 0.767327 Loss: 0.734092\n",
      "Epoch 23, CIFAR-10 Batch 1:  Valid Acc: 0.5718 Step Acc: 0.788366 Loss: 0.685944\n",
      "Epoch 24, CIFAR-10 Batch 1:  Valid Acc: 0.5688 Step Acc: 0.798267 Loss: 0.652612\n",
      "Epoch 25, CIFAR-10 Batch 1:  Valid Acc: 0.5804 Step Acc: 0.804455 Loss: 0.618057\n",
      "Epoch 26, CIFAR-10 Batch 1:  Valid Acc: 0.5754 Step Acc: 0.835396 Loss: 0.566555\n",
      "Epoch 27, CIFAR-10 Batch 1:  Valid Acc: 0.585 Step Acc: 0.844059 Loss: 0.518944\n",
      "Epoch 28, CIFAR-10 Batch 1:  Valid Acc: 0.582 Step Acc: 0.867574 Loss: 0.476677\n",
      "Epoch 29, CIFAR-10 Batch 1:  Valid Acc: 0.5798 Step Acc: 0.877475 Loss: 0.44144\n",
      "Epoch 30, CIFAR-10 Batch 1:  Valid Acc: 0.5794 Step Acc: 0.886139 Loss: 0.420139\n",
      "Epoch 31, CIFAR-10 Batch 1:  Valid Acc: 0.5808 Step Acc: 0.90099 Loss: 0.375931\n",
      "Epoch 32, CIFAR-10 Batch 1:  Valid Acc: 0.5786 Step Acc: 0.902228 Loss: 0.370117\n",
      "Epoch 33, CIFAR-10 Batch 1:  Valid Acc: 0.5794 Step Acc: 0.913366 Loss: 0.333039\n",
      "Epoch 34, CIFAR-10 Batch 1:  Valid Acc: 0.5832 Step Acc: 0.92203 Loss: 0.30698\n",
      "Epoch 35, CIFAR-10 Batch 1:  Valid Acc: 0.5778 Step Acc: 0.930693 Loss: 0.288394\n",
      "Epoch 36, CIFAR-10 Batch 1:  Valid Acc: 0.5732 Step Acc: 0.939356 Loss: 0.288141\n",
      "Epoch 37, CIFAR-10 Batch 1:  Valid Acc: 0.5718 Step Acc: 0.92203 Loss: 0.296413\n",
      "Epoch 38, CIFAR-10 Batch 1:  Valid Acc: 0.579 Step Acc: 0.950495 Loss: 0.234121\n",
      "Epoch 39, CIFAR-10 Batch 1:  Valid Acc: 0.5712 Step Acc: 0.94802 Loss: 0.229934\n",
      "Epoch 40, CIFAR-10 Batch 1:  Valid Acc: 0.5744 Step Acc: 0.957921 Loss: 0.20845\n",
      "Epoch 41, CIFAR-10 Batch 1:  Valid Acc: 0.5728 Step Acc: 0.955446 Loss: 0.195538\n",
      "Epoch 42, CIFAR-10 Batch 1:  Valid Acc: 0.5658 Step Acc: 0.964109 Loss: 0.171874\n",
      "Epoch 43, CIFAR-10 Batch 1:  Valid Acc: 0.5658 Step Acc: 0.970297 Loss: 0.163407\n",
      "Epoch 44, CIFAR-10 Batch 1:  Valid Acc: 0.5704 Step Acc: 0.972772 Loss: 0.150403\n",
      "Epoch 45, CIFAR-10 Batch 1:  Valid Acc: 0.5864 Step Acc: 0.977723 Loss: 0.128846\n",
      "Epoch 46, CIFAR-10 Batch 1:  Valid Acc: 0.5734 Step Acc: 0.97896 Loss: 0.140557\n",
      "Epoch 47, CIFAR-10 Batch 1:  Valid Acc: 0.5762 Step Acc: 0.972772 Loss: 0.121708\n",
      "Epoch 48, CIFAR-10 Batch 1:  Valid Acc: 0.5832 Step Acc: 0.982673 Loss: 0.0887664\n",
      "Epoch 49, CIFAR-10 Batch 1:  Valid Acc: 0.5856 Step Acc: 0.990099 Loss: 0.0761166\n",
      "Epoch 50, CIFAR-10 Batch 1:  Valid Acc: 0.5848 Step Acc: 0.988861 Loss: 0.0739016\n",
      "Epoch 51, CIFAR-10 Batch 1:  Valid Acc: 0.5854 Step Acc: 0.987624 Loss: 0.0661433\n",
      "Epoch 52, CIFAR-10 Batch 1:  Valid Acc: 0.5818 Step Acc: 0.987624 Loss: 0.0633148\n",
      "Epoch 53, CIFAR-10 Batch 1:  Valid Acc: 0.5786 Step Acc: 0.992574 Loss: 0.0618685\n",
      "Epoch 54, CIFAR-10 Batch 1:  Valid Acc: 0.5814 Step Acc: 0.992574 Loss: 0.0574756\n",
      "Epoch 55, CIFAR-10 Batch 1:  Valid Acc: 0.5854 Step Acc: 0.993812 Loss: 0.0494576\n",
      "Epoch 56, CIFAR-10 Batch 1:  Valid Acc: 0.5864 Step Acc: 0.995049 Loss: 0.0448489\n",
      "Epoch 57, CIFAR-10 Batch 1:  Valid Acc: 0.582 Step Acc: 0.995049 Loss: 0.0486604\n",
      "Epoch 58, CIFAR-10 Batch 1:  Valid Acc: 0.5754 Step Acc: 0.996287 Loss: 0.0506046\n",
      "Epoch 59, CIFAR-10 Batch 1:  Valid Acc: 0.5706 Step Acc: 0.992574 Loss: 0.0486374\n",
      "Epoch 60, CIFAR-10 Batch 1:  Valid Acc: 0.566 Step Acc: 0.996287 Loss: 0.0480802\n",
      "Epoch 61, CIFAR-10 Batch 1:  Valid Acc: 0.562 Step Acc: 0.995049 Loss: 0.0586387\n",
      "Epoch 62, CIFAR-10 Batch 1:  Valid Acc: 0.5794 Step Acc: 0.997525 Loss: 0.0428539\n",
      "Epoch 63, CIFAR-10 Batch 1:  Valid Acc: 0.5826 Step Acc: 0.997525 Loss: 0.0420602\n",
      "Epoch 64, CIFAR-10 Batch 1:  Valid Acc: 0.5774 Step Acc: 0.993812 Loss: 0.0453536\n",
      "Epoch 65, CIFAR-10 Batch 1:  Valid Acc: 0.57 Step Acc: 0.990099 Loss: 0.0508492\n",
      "Epoch 66, CIFAR-10 Batch 1:  Valid Acc: 0.5708 Step Acc: 0.995049 Loss: 0.0413523\n",
      "Epoch 67, CIFAR-10 Batch 1:  Valid Acc: 0.5662 Step Acc: 0.998762 Loss: 0.0333684\n",
      "Epoch 68, CIFAR-10 Batch 1:  Valid Acc: 0.5706 Step Acc: 0.997525 Loss: 0.0347104\n",
      "Epoch 69, CIFAR-10 Batch 1:  Valid Acc: 0.5732 Step Acc: 1.0 Loss: 0.026707\n",
      "Epoch 70, CIFAR-10 Batch 1:  Valid Acc: 0.576 Step Acc: 0.995049 Loss: 0.0294656\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Valid Acc: 0.1694 Step Acc: 0.149752 Loss: 2.2484\n",
      "Epoch  1, CIFAR-10 Batch 2:  Valid Acc: 0.3118 Step Acc: 0.294554 Loss: 1.99378\n",
      "Epoch  1, CIFAR-10 Batch 3:  Valid Acc: 0.3464 Step Acc: 0.367574 Loss: 1.81383\n",
      "Epoch  1, CIFAR-10 Batch 4:  Valid Acc: 0.3896 Step Acc: 0.371287 Loss: 1.7526\n",
      "Epoch  1, CIFAR-10 Batch 5:  Valid Acc: 0.3972 Step Acc: 0.417079 Loss: 1.69229\n",
      "Epoch  2, CIFAR-10 Batch 1:  Valid Acc: 0.4342 Step Acc: 0.429455 Loss: 1.63133\n",
      "Epoch  2, CIFAR-10 Batch 2:  Valid Acc: 0.453 Step Acc: 0.444307 Loss: 1.56388\n",
      "Epoch  2, CIFAR-10 Batch 3:  Valid Acc: 0.466 Step Acc: 0.477723 Loss: 1.43269\n",
      "Epoch  2, CIFAR-10 Batch 4:  Valid Acc: 0.4906 Step Acc: 0.483911 Loss: 1.41479\n",
      "Epoch  2, CIFAR-10 Batch 5:  Valid Acc: 0.4982 Step Acc: 0.517327 Loss: 1.3834\n",
      "Epoch  3, CIFAR-10 Batch 1:  Valid Acc: 0.5024 Step Acc: 0.509901 Loss: 1.39949\n",
      "Epoch  3, CIFAR-10 Batch 2:  Valid Acc: 0.516 Step Acc: 0.509901 Loss: 1.38938\n",
      "Epoch  3, CIFAR-10 Batch 3:  Valid Acc: 0.517 Step Acc: 0.533416 Loss: 1.25578\n",
      "Epoch  3, CIFAR-10 Batch 4:  Valid Acc: 0.5272 Step Acc: 0.555693 Loss: 1.25461\n",
      "Epoch  3, CIFAR-10 Batch 5:  Valid Acc: 0.5348 Step Acc: 0.586634 Loss: 1.24463\n",
      "Epoch  4, CIFAR-10 Batch 1:  Valid Acc: 0.5328 Step Acc: 0.554455 Loss: 1.26167\n",
      "Epoch  4, CIFAR-10 Batch 2:  Valid Acc: 0.5404 Step Acc: 0.539604 Loss: 1.30303\n",
      "Epoch  4, CIFAR-10 Batch 3:  Valid Acc: 0.5436 Step Acc: 0.57302 Loss: 1.14851\n",
      "Epoch  4, CIFAR-10 Batch 4:  Valid Acc: 0.5642 Step Acc: 0.596535 Loss: 1.15707\n",
      "Epoch  4, CIFAR-10 Batch 5:  Valid Acc: 0.5656 Step Acc: 0.634901 Loss: 1.1378\n",
      "Epoch  5, CIFAR-10 Batch 1:  Valid Acc: 0.5604 Step Acc: 0.580446 Loss: 1.18021\n",
      "Epoch  5, CIFAR-10 Batch 2:  Valid Acc: 0.57 Step Acc: 0.580446 Loss: 1.1918\n",
      "Epoch  5, CIFAR-10 Batch 3:  Valid Acc: 0.5712 Step Acc: 0.608911 Loss: 1.07079\n",
      "Epoch  5, CIFAR-10 Batch 4:  Valid Acc: 0.5924 Step Acc: 0.639851 Loss: 1.05325\n",
      "Epoch  5, CIFAR-10 Batch 5:  Valid Acc: 0.5926 Step Acc: 0.680693 Loss: 1.04125\n",
      "Epoch  6, CIFAR-10 Batch 1:  Valid Acc: 0.5762 Step Acc: 0.592822 Loss: 1.11684\n",
      "Epoch  6, CIFAR-10 Batch 2:  Valid Acc: 0.594 Step Acc: 0.617574 Loss: 1.10558\n",
      "Epoch  6, CIFAR-10 Batch 3:  Valid Acc: 0.5936 Step Acc: 0.639852 Loss: 0.993317\n",
      "Epoch  6, CIFAR-10 Batch 4:  Valid Acc: 0.6056 Step Acc: 0.652228 Loss: 0.983518\n",
      "Epoch  6, CIFAR-10 Batch 5:  Valid Acc: 0.6124 Step Acc: 0.689356 Loss: 0.960831\n",
      "Epoch  7, CIFAR-10 Batch 1:  Valid Acc: 0.6046 Step Acc: 0.634901 Loss: 1.01702\n",
      "Epoch  7, CIFAR-10 Batch 2:  Valid Acc: 0.6162 Step Acc: 0.658416 Loss: 1.02038\n",
      "Epoch  7, CIFAR-10 Batch 3:  Valid Acc: 0.6054 Step Acc: 0.664604 Loss: 0.92656\n",
      "Epoch  7, CIFAR-10 Batch 4:  Valid Acc: 0.6272 Step Acc: 0.689356 Loss: 0.904081\n",
      "Epoch  7, CIFAR-10 Batch 5:  Valid Acc: 0.6358 Step Acc: 0.746287 Loss: 0.880766\n",
      "Epoch  8, CIFAR-10 Batch 1:  Valid Acc: 0.6276 Step Acc: 0.667079 Loss: 0.940994\n",
      "Epoch  8, CIFAR-10 Batch 2:  Valid Acc: 0.6326 Step Acc: 0.67698 Loss: 0.957291\n",
      "Epoch  8, CIFAR-10 Batch 3:  Valid Acc: 0.6168 Step Acc: 0.679455 Loss: 0.891075\n",
      "Epoch  8, CIFAR-10 Batch 4:  Valid Acc: 0.6352 Step Acc: 0.712871 Loss: 0.842922\n",
      "Epoch  8, CIFAR-10 Batch 5:  Valid Acc: 0.6468 Step Acc: 0.751238 Loss: 0.816573\n",
      "Epoch  9, CIFAR-10 Batch 1:  Valid Acc: 0.6408 Step Acc: 0.685644 Loss: 0.888417\n",
      "Epoch  9, CIFAR-10 Batch 2:  Valid Acc: 0.6518 Step Acc: 0.704208 Loss: 0.874791\n",
      "Epoch  9, CIFAR-10 Batch 3:  Valid Acc: 0.634 Step Acc: 0.69802 Loss: 0.836181\n",
      "Epoch  9, CIFAR-10 Batch 4:  Valid Acc: 0.6468 Step Acc: 0.733911 Loss: 0.782781\n",
      "Epoch  9, CIFAR-10 Batch 5:  Valid Acc: 0.6492 Step Acc: 0.766089 Loss: 0.754829\n",
      "Epoch 10, CIFAR-10 Batch 1:  Valid Acc: 0.657 Step Acc: 0.716584 Loss: 0.819983\n",
      "Epoch 10, CIFAR-10 Batch 2:  Valid Acc: 0.6478 Step Acc: 0.727723 Loss: 0.837401\n",
      "Epoch 10, CIFAR-10 Batch 3:  Valid Acc: 0.6534 Step Acc: 0.738861 Loss: 0.745442\n",
      "Epoch 10, CIFAR-10 Batch 4:  Valid Acc: 0.6398 Step Acc: 0.742574 Loss: 0.756125\n",
      "Epoch 10, CIFAR-10 Batch 5:  Valid Acc: 0.6664 Step Acc: 0.787129 Loss: 0.699105\n",
      "Epoch 11, CIFAR-10 Batch 1:  Valid Acc: 0.6484 Step Acc: 0.722772 Loss: 0.815687\n",
      "Epoch 11, CIFAR-10 Batch 2:  Valid Acc: 0.6522 Step Acc: 0.74505 Loss: 0.788006\n",
      "Epoch 11, CIFAR-10 Batch 3:  Valid Acc: 0.6584 Step Acc: 0.751238 Loss: 0.72258\n",
      "Epoch 11, CIFAR-10 Batch 4:  Valid Acc: 0.6526 Step Acc: 0.757426 Loss: 0.695812\n",
      "Epoch 11, CIFAR-10 Batch 5:  Valid Acc: 0.6624 Step Acc: 0.804455 Loss: 0.662989\n",
      "Epoch 12, CIFAR-10 Batch 1:  Valid Acc: 0.6662 Step Acc: 0.752475 Loss: 0.730508\n",
      "Epoch 12, CIFAR-10 Batch 2:  Valid Acc: 0.6596 Step Acc: 0.753713 Loss: 0.719118\n",
      "Epoch 12, CIFAR-10 Batch 3:  Valid Acc: 0.6616 Step Acc: 0.774752 Loss: 0.660819\n",
      "Epoch 12, CIFAR-10 Batch 4:  Valid Acc: 0.6468 Step Acc: 0.79703 Loss: 0.628789\n",
      "Epoch 12, CIFAR-10 Batch 5:  Valid Acc: 0.6606 Step Acc: 0.804455 Loss: 0.63657\n",
      "Epoch 13, CIFAR-10 Batch 1:  Valid Acc: 0.6714 Step Acc: 0.772277 Loss: 0.6748\n",
      "Epoch 13, CIFAR-10 Batch 2:  Valid Acc: 0.677 Step Acc: 0.798267 Loss: 0.658856\n",
      "Epoch 13, CIFAR-10 Batch 3:  Valid Acc: 0.6694 Step Acc: 0.803218 Loss: 0.609315\n",
      "Epoch 13, CIFAR-10 Batch 4:  Valid Acc: 0.6588 Step Acc: 0.814356 Loss: 0.573994\n",
      "Epoch 13, CIFAR-10 Batch 5:  Valid Acc: 0.677 Step Acc: 0.826733 Loss: 0.568602\n",
      "Epoch 14, CIFAR-10 Batch 1:  Valid Acc: 0.6822 Step Acc: 0.784653 Loss: 0.629841\n",
      "Epoch 14, CIFAR-10 Batch 2:  Valid Acc: 0.6844 Step Acc: 0.811881 Loss: 0.604135\n",
      "Epoch 14, CIFAR-10 Batch 3:  Valid Acc: 0.6792 Step Acc: 0.832921 Loss: 0.551969\n",
      "Epoch 14, CIFAR-10 Batch 4:  Valid Acc: 0.676 Step Acc: 0.850248 Loss: 0.508673\n",
      "Epoch 14, CIFAR-10 Batch 5:  Valid Acc: 0.6812 Step Acc: 0.850248 Loss: 0.518396\n",
      "Epoch 15, CIFAR-10 Batch 1:  Valid Acc: 0.6804 Step Acc: 0.815594 Loss: 0.581599\n",
      "Epoch 15, CIFAR-10 Batch 2:  Valid Acc: 0.681 Step Acc: 0.821782 Loss: 0.574705\n",
      "Epoch 15, CIFAR-10 Batch 3:  Valid Acc: 0.6864 Step Acc: 0.836634 Loss: 0.49885\n",
      "Epoch 15, CIFAR-10 Batch 4:  Valid Acc: 0.6772 Step Acc: 0.862624 Loss: 0.459038\n",
      "Epoch 15, CIFAR-10 Batch 5:  Valid Acc: 0.685 Step Acc: 0.862624 Loss: 0.460518\n",
      "Epoch 16, CIFAR-10 Batch 1:  Valid Acc: 0.6916 Step Acc: 0.835396 Loss: 0.507954\n",
      "Epoch 16, CIFAR-10 Batch 2:  Valid Acc: 0.6994 Step Acc: 0.85396 Loss: 0.505967\n",
      "Epoch 16, CIFAR-10 Batch 3:  Valid Acc: 0.6884 Step Acc: 0.85396 Loss: 0.466781\n",
      "Epoch 16, CIFAR-10 Batch 4:  Valid Acc: 0.6776 Step Acc: 0.873762 Loss: 0.436018\n",
      "Epoch 16, CIFAR-10 Batch 5:  Valid Acc: 0.6658 Step Acc: 0.863861 Loss: 0.470056\n",
      "Epoch 17, CIFAR-10 Batch 1:  Valid Acc: 0.6836 Step Acc: 0.845297 Loss: 0.474421\n",
      "Epoch 17, CIFAR-10 Batch 2:  Valid Acc: 0.6846 Step Acc: 0.845297 Loss: 0.501036\n",
      "Epoch 17, CIFAR-10 Batch 3:  Valid Acc: 0.6744 Step Acc: 0.847772 Loss: 0.457736\n",
      "Epoch 17, CIFAR-10 Batch 4:  Valid Acc: 0.662 Step Acc: 0.858911 Loss: 0.432389\n",
      "Epoch 17, CIFAR-10 Batch 5:  Valid Acc: 0.6746 Step Acc: 0.883663 Loss: 0.405317\n",
      "Epoch 18, CIFAR-10 Batch 1:  Valid Acc: 0.6804 Step Acc: 0.861386 Loss: 0.441805\n",
      "Epoch 18, CIFAR-10 Batch 2:  Valid Acc: 0.6962 Step Acc: 0.883663 Loss: 0.424037\n",
      "Epoch 18, CIFAR-10 Batch 3:  Valid Acc: 0.6914 Step Acc: 0.892327 Loss: 0.384086\n",
      "Epoch 18, CIFAR-10 Batch 4:  Valid Acc: 0.6888 Step Acc: 0.902228 Loss: 0.347255\n",
      "Epoch 18, CIFAR-10 Batch 5:  Valid Acc: 0.6924 Step Acc: 0.915842 Loss: 0.334623\n",
      "Epoch 19, CIFAR-10 Batch 1:  Valid Acc: 0.687 Step Acc: 0.881188 Loss: 0.385469\n",
      "Epoch 19, CIFAR-10 Batch 2:  Valid Acc: 0.6872 Step Acc: 0.889851 Loss: 0.400923\n",
      "Epoch 19, CIFAR-10 Batch 3:  Valid Acc: 0.694 Step Acc: 0.912129 Loss: 0.348833\n",
      "Epoch 19, CIFAR-10 Batch 4:  Valid Acc: 0.6922 Step Acc: 0.90594 Loss: 0.306875\n",
      "Epoch 19, CIFAR-10 Batch 5:  Valid Acc: 0.6954 Step Acc: 0.936881 Loss: 0.287708\n",
      "Epoch 20, CIFAR-10 Batch 1:  Valid Acc: 0.689 Step Acc: 0.903465 Loss: 0.350667\n",
      "Epoch 20, CIFAR-10 Batch 2:  Valid Acc: 0.6962 Step Acc: 0.915842 Loss: 0.335851\n",
      "Epoch 20, CIFAR-10 Batch 3:  Valid Acc: 0.6868 Step Acc: 0.919554 Loss: 0.339847\n",
      "Epoch 20, CIFAR-10 Batch 4:  Valid Acc: 0.688 Step Acc: 0.923267 Loss: 0.288633\n",
      "Epoch 20, CIFAR-10 Batch 5:  Valid Acc: 0.69 Step Acc: 0.945544 Loss: 0.256248\n",
      "Epoch 21, CIFAR-10 Batch 1:  Valid Acc: 0.694 Step Acc: 0.917079 Loss: 0.290625\n",
      "Epoch 21, CIFAR-10 Batch 2:  Valid Acc: 0.7002 Step Acc: 0.92203 Loss: 0.293836\n",
      "Epoch 21, CIFAR-10 Batch 3:  Valid Acc: 0.6938 Step Acc: 0.929455 Loss: 0.289459\n",
      "Epoch 21, CIFAR-10 Batch 4:  Valid Acc: 0.6918 Step Acc: 0.935643 Loss: 0.243327\n",
      "Epoch 21, CIFAR-10 Batch 5:  Valid Acc: 0.696 Step Acc: 0.960396 Loss: 0.218694\n",
      "Epoch 22, CIFAR-10 Batch 1:  Valid Acc: 0.7016 Step Acc: 0.938119 Loss: 0.253997\n",
      "Epoch 22, CIFAR-10 Batch 2:  Valid Acc: 0.6914 Step Acc: 0.930693 Loss: 0.265827\n",
      "Epoch 22, CIFAR-10 Batch 3:  Valid Acc: 0.6782 Step Acc: 0.92203 Loss: 0.298119\n",
      "Epoch 22, CIFAR-10 Batch 4:  Valid Acc: 0.6882 Step Acc: 0.938119 Loss: 0.235268\n",
      "Epoch 22, CIFAR-10 Batch 5:  Valid Acc: 0.696 Step Acc: 0.955446 Loss: 0.198147\n",
      "Epoch 23, CIFAR-10 Batch 1:  Valid Acc: 0.705 Step Acc: 0.941832 Loss: 0.227153\n",
      "Epoch 23, CIFAR-10 Batch 2:  Valid Acc: 0.685 Step Acc: 0.936881 Loss: 0.23045\n",
      "Epoch 23, CIFAR-10 Batch 3:  Valid Acc: 0.6864 Step Acc: 0.935644 Loss: 0.240326\n",
      "Epoch 23, CIFAR-10 Batch 4:  Valid Acc: 0.6808 Step Acc: 0.950495 Loss: 0.230114\n",
      "Epoch 23, CIFAR-10 Batch 5:  Valid Acc: 0.7014 Step Acc: 0.959158 Loss: 0.184873\n",
      "Epoch 24, CIFAR-10 Batch 1:  Valid Acc: 0.7034 Step Acc: 0.94802 Loss: 0.208463\n",
      "Epoch 24, CIFAR-10 Batch 2:  Valid Acc: 0.7006 Step Acc: 0.950495 Loss: 0.196601\n",
      "Epoch 24, CIFAR-10 Batch 3:  Valid Acc: 0.6904 Step Acc: 0.94802 Loss: 0.216603\n",
      "Epoch 24, CIFAR-10 Batch 4:  Valid Acc: 0.692 Step Acc: 0.961634 Loss: 0.187519\n",
      "Epoch 24, CIFAR-10 Batch 5:  Valid Acc: 0.6924 Step Acc: 0.959158 Loss: 0.169115\n",
      "Epoch 25, CIFAR-10 Batch 1:  Valid Acc: 0.704 Step Acc: 0.957921 Loss: 0.181674\n",
      "Epoch 25, CIFAR-10 Batch 2:  Valid Acc: 0.6904 Step Acc: 0.960396 Loss: 0.16545\n",
      "Epoch 25, CIFAR-10 Batch 3:  Valid Acc: 0.6962 Step Acc: 0.955445 Loss: 0.183323\n",
      "Epoch 25, CIFAR-10 Batch 4:  Valid Acc: 0.6958 Step Acc: 0.971535 Loss: 0.149967\n",
      "Epoch 25, CIFAR-10 Batch 5:  Valid Acc: 0.6972 Step Acc: 0.970297 Loss: 0.139827\n",
      "Epoch 26, CIFAR-10 Batch 1:  Valid Acc: 0.7 Step Acc: 0.965346 Loss: 0.160969\n",
      "Epoch 26, CIFAR-10 Batch 2:  Valid Acc: 0.6896 Step Acc: 0.962871 Loss: 0.162676\n",
      "Epoch 26, CIFAR-10 Batch 3:  Valid Acc: 0.6846 Step Acc: 0.962871 Loss: 0.169313\n",
      "Epoch 26, CIFAR-10 Batch 4:  Valid Acc: 0.6756 Step Acc: 0.967822 Loss: 0.164176\n",
      "Epoch 26, CIFAR-10 Batch 5:  Valid Acc: 0.6828 Step Acc: 0.971535 Loss: 0.143613\n",
      "Epoch 27, CIFAR-10 Batch 1:  Valid Acc: 0.7054 Step Acc: 0.960396 Loss: 0.14653\n",
      "Epoch 27, CIFAR-10 Batch 2:  Valid Acc: 0.7012 Step Acc: 0.975248 Loss: 0.136037\n",
      "Epoch 27, CIFAR-10 Batch 3:  Valid Acc: 0.701 Step Acc: 0.966584 Loss: 0.137843\n",
      "Epoch 27, CIFAR-10 Batch 4:  Valid Acc: 0.6826 Step Acc: 0.971535 Loss: 0.132246\n",
      "Epoch 27, CIFAR-10 Batch 5:  Valid Acc: 0.6804 Step Acc: 0.980198 Loss: 0.137618\n",
      "Epoch 28, CIFAR-10 Batch 1:  Valid Acc: 0.6964 Step Acc: 0.962871 Loss: 0.151407\n",
      "Epoch 28, CIFAR-10 Batch 2:  Valid Acc: 0.6886 Step Acc: 0.97896 Loss: 0.129684\n",
      "Epoch 28, CIFAR-10 Batch 3:  Valid Acc: 0.6846 Step Acc: 0.971535 Loss: 0.151282\n",
      "Epoch 28, CIFAR-10 Batch 4:  Valid Acc: 0.6764 Step Acc: 0.972772 Loss: 0.143872\n",
      "Epoch 28, CIFAR-10 Batch 5:  Valid Acc: 0.6836 Step Acc: 0.97896 Loss: 0.130045\n",
      "Epoch 29, CIFAR-10 Batch 1:  Valid Acc: 0.6724 Step Acc: 0.959158 Loss: 0.171079\n",
      "Epoch 29, CIFAR-10 Batch 2:  Valid Acc: 0.6968 Step Acc: 0.976485 Loss: 0.146764\n",
      "Epoch 29, CIFAR-10 Batch 3:  Valid Acc: 0.7042 Step Acc: 0.981436 Loss: 0.127277\n",
      "Epoch 29, CIFAR-10 Batch 4:  Valid Acc: 0.6972 Step Acc: 0.982673 Loss: 0.102316\n",
      "Epoch 29, CIFAR-10 Batch 5:  Valid Acc: 0.7048 Step Acc: 0.985149 Loss: 0.0842791\n",
      "Epoch 30, CIFAR-10 Batch 1:  Valid Acc: 0.6994 Step Acc: 0.980198 Loss: 0.104551\n",
      "Epoch 30, CIFAR-10 Batch 2:  Valid Acc: 0.7018 Step Acc: 0.980198 Loss: 0.0982339\n",
      "Epoch 30, CIFAR-10 Batch 3:  Valid Acc: 0.7074 Step Acc: 0.981436 Loss: 0.107898\n",
      "Epoch 30, CIFAR-10 Batch 4:  Valid Acc: 0.7042 Step Acc: 0.985149 Loss: 0.0852256\n",
      "Epoch 30, CIFAR-10 Batch 5:  Valid Acc: 0.703 Step Acc: 0.991337 Loss: 0.0770742\n",
      "Epoch 31, CIFAR-10 Batch 1:  Valid Acc: 0.6998 Step Acc: 0.987624 Loss: 0.0881505\n",
      "Epoch 31, CIFAR-10 Batch 2:  Valid Acc: 0.7134 Step Acc: 0.987624 Loss: 0.0781037\n",
      "Epoch 31, CIFAR-10 Batch 3:  Valid Acc: 0.6998 Step Acc: 0.985149 Loss: 0.081998\n",
      "Epoch 31, CIFAR-10 Batch 4:  Valid Acc: 0.6988 Step Acc: 0.988861 Loss: 0.0636057\n",
      "Epoch 31, CIFAR-10 Batch 5:  Valid Acc: 0.6984 Step Acc: 0.990099 Loss: 0.068278\n",
      "Epoch 32, CIFAR-10 Batch 1:  Valid Acc: 0.7042 Step Acc: 0.992574 Loss: 0.0672303\n",
      "Epoch 32, CIFAR-10 Batch 2:  Valid Acc: 0.7092 Step Acc: 0.990099 Loss: 0.0620465\n",
      "Epoch 32, CIFAR-10 Batch 3:  Valid Acc: 0.7094 Step Acc: 0.991337 Loss: 0.0640477\n",
      "Epoch 32, CIFAR-10 Batch 4:  Valid Acc: 0.6998 Step Acc: 0.990099 Loss: 0.060853\n",
      "Epoch 32, CIFAR-10 Batch 5:  Valid Acc: 0.699 Step Acc: 0.996287 Loss: 0.0530132\n",
      "Epoch 33, CIFAR-10 Batch 1:  Valid Acc: 0.7038 Step Acc: 0.993812 Loss: 0.0598841\n",
      "Epoch 33, CIFAR-10 Batch 2:  Valid Acc: 0.7094 Step Acc: 0.991337 Loss: 0.0521373\n",
      "Epoch 33, CIFAR-10 Batch 3:  Valid Acc: 0.7064 Step Acc: 0.991337 Loss: 0.0580985\n",
      "Epoch 33, CIFAR-10 Batch 4:  Valid Acc: 0.7054 Step Acc: 0.993812 Loss: 0.0535614\n",
      "Epoch 33, CIFAR-10 Batch 5:  Valid Acc: 0.7002 Step Acc: 0.998762 Loss: 0.0406294\n",
      "Epoch 34, CIFAR-10 Batch 1:  Valid Acc: 0.698 Step Acc: 0.992574 Loss: 0.0564927\n",
      "Epoch 34, CIFAR-10 Batch 2:  Valid Acc: 0.6896 Step Acc: 0.990099 Loss: 0.0619989\n",
      "Epoch 34, CIFAR-10 Batch 3:  Valid Acc: 0.6968 Step Acc: 0.991337 Loss: 0.0608861\n",
      "Epoch 34, CIFAR-10 Batch 4:  Valid Acc: 0.6928 Step Acc: 0.986386 Loss: 0.0559255\n",
      "Epoch 34, CIFAR-10 Batch 5:  Valid Acc: 0.7026 Step Acc: 0.996287 Loss: 0.0444475\n",
      "Epoch 35, CIFAR-10 Batch 1:  Valid Acc: 0.7076 Step Acc: 0.993812 Loss: 0.0463184\n",
      "Epoch 35, CIFAR-10 Batch 2:  Valid Acc: 0.703 Step Acc: 0.992574 Loss: 0.0461822\n",
      "Epoch 35, CIFAR-10 Batch 3:  Valid Acc: 0.7042 Step Acc: 0.993812 Loss: 0.0487715\n",
      "Epoch 35, CIFAR-10 Batch 4:  Valid Acc: 0.708 Step Acc: 0.995049 Loss: 0.0399098\n",
      "Epoch 35, CIFAR-10 Batch 5:  Valid Acc: 0.7108 Step Acc: 0.998762 Loss: 0.0383044\n",
      "Epoch 36, CIFAR-10 Batch 1:  Valid Acc: 0.714 Step Acc: 0.992574 Loss: 0.0390589\n",
      "Epoch 36, CIFAR-10 Batch 2:  Valid Acc: 0.711 Step Acc: 0.998762 Loss: 0.03968\n",
      "Epoch 36, CIFAR-10 Batch 3:  Valid Acc: 0.7112 Step Acc: 0.996287 Loss: 0.0379532\n",
      "Epoch 36, CIFAR-10 Batch 4:  Valid Acc: 0.717 Step Acc: 0.997525 Loss: 0.0338027\n",
      "Epoch 36, CIFAR-10 Batch 5:  Valid Acc: 0.7126 Step Acc: 0.996287 Loss: 0.0351839\n",
      "Epoch 37, CIFAR-10 Batch 1:  Valid Acc: 0.7056 Step Acc: 0.988861 Loss: 0.0463001\n",
      "Epoch 37, CIFAR-10 Batch 2:  Valid Acc: 0.713 Step Acc: 0.995049 Loss: 0.0339463\n",
      "Epoch 37, CIFAR-10 Batch 3:  Valid Acc: 0.7156 Step Acc: 0.998762 Loss: 0.029035\n",
      "Epoch 37, CIFAR-10 Batch 4:  Valid Acc: 0.71 Step Acc: 0.995049 Loss: 0.0315854\n",
      "Epoch 37, CIFAR-10 Batch 5:  Valid Acc: 0.7088 Step Acc: 1.0 Loss: 0.0251913\n",
      "Epoch 38, CIFAR-10 Batch 1:  Valid Acc: 0.7068 Step Acc: 0.993812 Loss: 0.0359114\n",
      "Epoch 38, CIFAR-10 Batch 2:  Valid Acc: 0.6976 Step Acc: 0.991337 Loss: 0.042494\n",
      "Epoch 38, CIFAR-10 Batch 3:  Valid Acc: 0.7024 Step Acc: 0.997525 Loss: 0.0411755\n",
      "Epoch 38, CIFAR-10 Batch 4:  Valid Acc: 0.714 Step Acc: 0.997525 Loss: 0.0259343\n",
      "Epoch 38, CIFAR-10 Batch 5:  Valid Acc: 0.7074 Step Acc: 0.996287 Loss: 0.0305743\n",
      "Epoch 39, CIFAR-10 Batch 1:  Valid Acc: 0.711 Step Acc: 0.997525 Loss: 0.0265207\n",
      "Epoch 39, CIFAR-10 Batch 2:  Valid Acc: 0.7084 Step Acc: 0.99505 Loss: 0.0365869\n",
      "Epoch 39, CIFAR-10 Batch 3:  Valid Acc: 0.7082 Step Acc: 0.998762 Loss: 0.0256822\n",
      "Epoch 39, CIFAR-10 Batch 4:  Valid Acc: 0.7134 Step Acc: 0.997525 Loss: 0.0260295\n",
      "Epoch 39, CIFAR-10 Batch 5:  Valid Acc: 0.7146 Step Acc: 0.998762 Loss: 0.0171596\n",
      "Epoch 40, CIFAR-10 Batch 1:  Valid Acc: 0.7146 Step Acc: 0.995049 Loss: 0.0252613\n",
      "Epoch 40, CIFAR-10 Batch 2:  Valid Acc: 0.7232 Step Acc: 0.997525 Loss: 0.0217364\n",
      "Epoch 40, CIFAR-10 Batch 3:  Valid Acc: 0.7024 Step Acc: 0.997525 Loss: 0.0240869\n",
      "Epoch 40, CIFAR-10 Batch 4:  Valid Acc: 0.7126 Step Acc: 0.997525 Loss: 0.0205887\n",
      "Epoch 40, CIFAR-10 Batch 5:  Valid Acc: 0.7054 Step Acc: 1.0 Loss: 0.0185507\n",
      "Epoch 41, CIFAR-10 Batch 1:  Valid Acc: 0.7154 Step Acc: 1.0 Loss: 0.0167061\n",
      "Epoch 41, CIFAR-10 Batch 2:  Valid Acc: 0.713 Step Acc: 0.996287 Loss: 0.0213514\n",
      "Epoch 41, CIFAR-10 Batch 3:  Valid Acc: 0.7098 Step Acc: 1.0 Loss: 0.0139866\n",
      "Epoch 41, CIFAR-10 Batch 4:  Valid Acc: 0.719 Step Acc: 1.0 Loss: 0.013605\n",
      "Epoch 41, CIFAR-10 Batch 5:  Valid Acc: 0.7102 Step Acc: 1.0 Loss: 0.0148596\n",
      "Epoch 42, CIFAR-10 Batch 1:  Valid Acc: 0.713 Step Acc: 0.998762 Loss: 0.0180587\n",
      "Epoch 42, CIFAR-10 Batch 2:  Valid Acc: 0.7194 Step Acc: 0.998762 Loss: 0.0168025\n",
      "Epoch 42, CIFAR-10 Batch 3:  Valid Acc: 0.7142 Step Acc: 1.0 Loss: 0.0106687\n",
      "Epoch 42, CIFAR-10 Batch 4:  Valid Acc: 0.7176 Step Acc: 1.0 Loss: 0.0108768\n",
      "Epoch 42, CIFAR-10 Batch 5:  Valid Acc: 0.7146 Step Acc: 1.0 Loss: 0.0120785\n",
      "Epoch 43, CIFAR-10 Batch 1:  Valid Acc: 0.7152 Step Acc: 1.0 Loss: 0.012584\n",
      "Epoch 43, CIFAR-10 Batch 2:  Valid Acc: 0.7222 Step Acc: 0.998762 Loss: 0.0131636\n",
      "Epoch 43, CIFAR-10 Batch 3:  Valid Acc: 0.7208 Step Acc: 0.998762 Loss: 0.0118551\n",
      "Epoch 43, CIFAR-10 Batch 4:  Valid Acc: 0.7178 Step Acc: 1.0 Loss: 0.0113786\n",
      "Epoch 43, CIFAR-10 Batch 5:  Valid Acc: 0.7132 Step Acc: 0.998762 Loss: 0.0132421\n",
      "Epoch 44, CIFAR-10 Batch 1:  Valid Acc: 0.7142 Step Acc: 0.997525 Loss: 0.012703\n",
      "Epoch 44, CIFAR-10 Batch 2:  Valid Acc: 0.712 Step Acc: 0.998762 Loss: 0.014509\n",
      "Epoch 44, CIFAR-10 Batch 3:  Valid Acc: 0.7212 Step Acc: 1.0 Loss: 0.00853933\n",
      "Epoch 44, CIFAR-10 Batch 4:  Valid Acc: 0.7192 Step Acc: 1.0 Loss: 0.00922786\n",
      "Epoch 44, CIFAR-10 Batch 5:  Valid Acc: 0.7178 Step Acc: 1.0 Loss: 0.00862054\n",
      "Epoch 45, CIFAR-10 Batch 1:  Valid Acc: 0.7092 Step Acc: 1.0 Loss: 0.011741\n",
      "Epoch 45, CIFAR-10 Batch 2:  Valid Acc: 0.7134 Step Acc: 0.998762 Loss: 0.0114784\n",
      "Epoch 45, CIFAR-10 Batch 3:  Valid Acc: 0.715 Step Acc: 1.0 Loss: 0.00980031\n",
      "Epoch 45, CIFAR-10 Batch 4:  Valid Acc: 0.7136 Step Acc: 1.0 Loss: 0.00903752\n",
      "Epoch 45, CIFAR-10 Batch 5:  Valid Acc: 0.716 Step Acc: 1.0 Loss: 0.00651828\n",
      "Epoch 46, CIFAR-10 Batch 1:  Valid Acc: 0.7062 Step Acc: 1.0 Loss: 0.0105801\n",
      "Epoch 46, CIFAR-10 Batch 2:  Valid Acc: 0.7162 Step Acc: 1.0 Loss: 0.00921217\n",
      "Epoch 46, CIFAR-10 Batch 3:  Valid Acc: 0.7036 Step Acc: 1.0 Loss: 0.0129406\n",
      "Epoch 46, CIFAR-10 Batch 4:  Valid Acc: 0.7148 Step Acc: 1.0 Loss: 0.00739537\n",
      "Epoch 46, CIFAR-10 Batch 5:  Valid Acc: 0.7184 Step Acc: 1.0 Loss: 0.00681883\n",
      "Epoch 47, CIFAR-10 Batch 1:  Valid Acc: 0.7138 Step Acc: 1.0 Loss: 0.00782105\n",
      "Epoch 47, CIFAR-10 Batch 2:  Valid Acc: 0.7212 Step Acc: 0.998762 Loss: 0.00823041\n",
      "Epoch 47, CIFAR-10 Batch 3:  Valid Acc: 0.7176 Step Acc: 1.0 Loss: 0.00741692\n",
      "Epoch 47, CIFAR-10 Batch 4:  Valid Acc: 0.7088 Step Acc: 1.0 Loss: 0.00662394\n",
      "Epoch 47, CIFAR-10 Batch 5:  Valid Acc: 0.7236 Step Acc: 1.0 Loss: 0.00684054\n",
      "Epoch 48, CIFAR-10 Batch 1:  Valid Acc: 0.7134 Step Acc: 1.0 Loss: 0.00764477\n",
      "Epoch 48, CIFAR-10 Batch 2:  Valid Acc: 0.716 Step Acc: 0.998762 Loss: 0.0079318\n",
      "Epoch 48, CIFAR-10 Batch 3:  Valid Acc: 0.718 Step Acc: 1.0 Loss: 0.00611456\n",
      "Epoch 48, CIFAR-10 Batch 4:  Valid Acc: 0.7128 Step Acc: 1.0 Loss: 0.006564\n",
      "Epoch 48, CIFAR-10 Batch 5:  Valid Acc: 0.7162 Step Acc: 1.0 Loss: 0.00635482\n",
      "Epoch 49, CIFAR-10 Batch 1:  Valid Acc: 0.7002 Step Acc: 0.997525 Loss: 0.012099\n",
      "Epoch 49, CIFAR-10 Batch 2:  Valid Acc: 0.7236 Step Acc: 0.998762 Loss: 0.00728185\n",
      "Epoch 49, CIFAR-10 Batch 3:  Valid Acc: 0.721 Step Acc: 1.0 Loss: 0.00508986\n",
      "Epoch 49, CIFAR-10 Batch 4:  Valid Acc: 0.7212 Step Acc: 1.0 Loss: 0.00434106\n",
      "Epoch 49, CIFAR-10 Batch 5:  Valid Acc: 0.724 Step Acc: 1.0 Loss: 0.00552337\n",
      "Epoch 50, CIFAR-10 Batch 1:  Valid Acc: 0.7096 Step Acc: 1.0 Loss: 0.00821788\n",
      "Epoch 50, CIFAR-10 Batch 2:  Valid Acc: 0.713 Step Acc: 0.997525 Loss: 0.010234\n",
      "Epoch 50, CIFAR-10 Batch 3:  Valid Acc: 0.7172 Step Acc: 1.0 Loss: 0.00527631\n",
      "Epoch 50, CIFAR-10 Batch 4:  Valid Acc: 0.7118 Step Acc: 1.0 Loss: 0.00575817\n",
      "Epoch 50, CIFAR-10 Batch 5:  Valid Acc: 0.7182 Step Acc: 1.0 Loss: 0.00489591\n",
      "Epoch 51, CIFAR-10 Batch 1:  Valid Acc: 0.7108 Step Acc: 1.0 Loss: 0.0054435\n",
      "Epoch 51, CIFAR-10 Batch 2:  Valid Acc: 0.7152 Step Acc: 0.998762 Loss: 0.0066671\n",
      "Epoch 51, CIFAR-10 Batch 3:  Valid Acc: 0.7166 Step Acc: 1.0 Loss: 0.0062367\n",
      "Epoch 51, CIFAR-10 Batch 4:  Valid Acc: 0.716 Step Acc: 1.0 Loss: 0.00468364\n",
      "Epoch 51, CIFAR-10 Batch 5:  Valid Acc: 0.7166 Step Acc: 1.0 Loss: 0.00381126\n",
      "Epoch 52, CIFAR-10 Batch 1:  Valid Acc: 0.7176 Step Acc: 1.0 Loss: 0.00504394\n",
      "Epoch 52, CIFAR-10 Batch 2:  Valid Acc: 0.711 Step Acc: 0.998762 Loss: 0.00587098\n",
      "Epoch 52, CIFAR-10 Batch 3:  Valid Acc: 0.714 Step Acc: 1.0 Loss: 0.00524092\n",
      "Epoch 52, CIFAR-10 Batch 4:  Valid Acc: 0.7172 Step Acc: 1.0 Loss: 0.00337105\n",
      "Epoch 52, CIFAR-10 Batch 5:  Valid Acc: 0.709 Step Acc: 1.0 Loss: 0.00380451\n",
      "Epoch 53, CIFAR-10 Batch 1:  Valid Acc: 0.7178 Step Acc: 1.0 Loss: 0.00468005\n",
      "Epoch 53, CIFAR-10 Batch 2:  Valid Acc: 0.7206 Step Acc: 0.998762 Loss: 0.0044399\n",
      "Epoch 53, CIFAR-10 Batch 3:  Valid Acc: 0.7118 Step Acc: 1.0 Loss: 0.00554773\n",
      "Epoch 53, CIFAR-10 Batch 4:  Valid Acc: 0.7214 Step Acc: 1.0 Loss: 0.00297365\n",
      "Epoch 53, CIFAR-10 Batch 5:  Valid Acc: 0.7202 Step Acc: 1.0 Loss: 0.00273335\n",
      "Epoch 54, CIFAR-10 Batch 1:  Valid Acc: 0.7148 Step Acc: 1.0 Loss: 0.00362519\n",
      "Epoch 54, CIFAR-10 Batch 2:  Valid Acc: 0.7128 Step Acc: 1.0 Loss: 0.00416495\n",
      "Epoch 54, CIFAR-10 Batch 3:  Valid Acc: 0.7168 Step Acc: 1.0 Loss: 0.00407891\n",
      "Epoch 54, CIFAR-10 Batch 4:  Valid Acc: 0.7204 Step Acc: 1.0 Loss: 0.00333333\n",
      "Epoch 54, CIFAR-10 Batch 5:  Valid Acc: 0.7202 Step Acc: 1.0 Loss: 0.00291506\n",
      "Epoch 55, CIFAR-10 Batch 1:  Valid Acc: 0.7244 Step Acc: 1.0 Loss: 0.00279801\n",
      "Epoch 55, CIFAR-10 Batch 2:  Valid Acc: 0.719 Step Acc: 0.998762 Loss: 0.00483228\n",
      "Epoch 55, CIFAR-10 Batch 3:  Valid Acc: 0.716 Step Acc: 1.0 Loss: 0.00434737\n",
      "Epoch 55, CIFAR-10 Batch 4:  Valid Acc: 0.7164 Step Acc: 1.0 Loss: 0.00384912\n",
      "Epoch 55, CIFAR-10 Batch 5:  Valid Acc: 0.7138 Step Acc: 1.0 Loss: 0.00308009\n",
      "Epoch 56, CIFAR-10 Batch 1:  Valid Acc: 0.7198 Step Acc: 1.0 Loss: 0.00288339\n",
      "Epoch 56, CIFAR-10 Batch 2:  Valid Acc: 0.7166 Step Acc: 1.0 Loss: 0.00274925\n",
      "Epoch 56, CIFAR-10 Batch 3:  Valid Acc: 0.7128 Step Acc: 1.0 Loss: 0.00446063\n",
      "Epoch 56, CIFAR-10 Batch 4:  Valid Acc: 0.7152 Step Acc: 1.0 Loss: 0.00254952\n",
      "Epoch 56, CIFAR-10 Batch 5:  Valid Acc: 0.7142 Step Acc: 1.0 Loss: 0.00247316\n",
      "Epoch 57, CIFAR-10 Batch 1:  Valid Acc: 0.7202 Step Acc: 1.0 Loss: 0.00271711\n",
      "Epoch 57, CIFAR-10 Batch 2:  Valid Acc: 0.7134 Step Acc: 1.0 Loss: 0.00278954\n",
      "Epoch 57, CIFAR-10 Batch 3:  Valid Acc: 0.7144 Step Acc: 1.0 Loss: 0.00216142\n",
      "Epoch 57, CIFAR-10 Batch 4:  Valid Acc: 0.7224 Step Acc: 1.0 Loss: 0.00292353\n",
      "Epoch 57, CIFAR-10 Batch 5:  Valid Acc: 0.7144 Step Acc: 1.0 Loss: 0.00231546\n",
      "Epoch 58, CIFAR-10 Batch 1:  Valid Acc: 0.7202 Step Acc: 1.0 Loss: 0.00248487\n",
      "Epoch 58, CIFAR-10 Batch 2:  Valid Acc: 0.7198 Step Acc: 1.0 Loss: 0.00184993\n",
      "Epoch 58, CIFAR-10 Batch 3:  Valid Acc: 0.7204 Step Acc: 1.0 Loss: 0.00233551\n",
      "Epoch 58, CIFAR-10 Batch 4:  Valid Acc: 0.7176 Step Acc: 1.0 Loss: 0.00161976\n",
      "Epoch 58, CIFAR-10 Batch 5:  Valid Acc: 0.7148 Step Acc: 1.0 Loss: 0.00238363\n",
      "Epoch 59, CIFAR-10 Batch 1:  Valid Acc: 0.722 Step Acc: 1.0 Loss: 0.00223132\n",
      "Epoch 59, CIFAR-10 Batch 2:  Valid Acc: 0.7232 Step Acc: 1.0 Loss: 0.0024872\n",
      "Epoch 59, CIFAR-10 Batch 3:  Valid Acc: 0.7184 Step Acc: 1.0 Loss: 0.0029516\n",
      "Epoch 59, CIFAR-10 Batch 4:  Valid Acc: 0.7202 Step Acc: 1.0 Loss: 0.00167297\n",
      "Epoch 59, CIFAR-10 Batch 5:  Valid Acc: 0.7172 Step Acc: 1.0 Loss: 0.00259559\n",
      "Epoch 60, CIFAR-10 Batch 1:  Valid Acc: 0.7216 Step Acc: 1.0 Loss: 0.00236553\n",
      "Epoch 60, CIFAR-10 Batch 2:  Valid Acc: 0.7176 Step Acc: 0.998762 Loss: 0.00266989\n",
      "Epoch 60, CIFAR-10 Batch 3:  Valid Acc: 0.7158 Step Acc: 1.0 Loss: 0.0022532\n",
      "Epoch 60, CIFAR-10 Batch 4:  Valid Acc: 0.7186 Step Acc: 1.0 Loss: 0.00151421\n",
      "Epoch 60, CIFAR-10 Batch 5:  Valid Acc: 0.7232 Step Acc: 1.0 Loss: 0.0019317\n",
      "Epoch 61, CIFAR-10 Batch 1:  Valid Acc: 0.717 Step Acc: 1.0 Loss: 0.00209061\n",
      "Epoch 61, CIFAR-10 Batch 2:  Valid Acc: 0.7188 Step Acc: 1.0 Loss: 0.00218748\n",
      "Epoch 61, CIFAR-10 Batch 3:  Valid Acc: 0.7184 Step Acc: 1.0 Loss: 0.00193986\n",
      "Epoch 61, CIFAR-10 Batch 4:  Valid Acc: 0.7118 Step Acc: 1.0 Loss: 0.00175926\n",
      "Epoch 61, CIFAR-10 Batch 5:  Valid Acc: 0.7088 Step Acc: 0.998762 Loss: 0.00457801\n",
      "Epoch 62, CIFAR-10 Batch 1:  Valid Acc: 0.7202 Step Acc: 1.0 Loss: 0.00183666\n",
      "Epoch 62, CIFAR-10 Batch 2:  Valid Acc: 0.72 Step Acc: 1.0 Loss: 0.00235159\n",
      "Epoch 62, CIFAR-10 Batch 3:  Valid Acc: 0.712 Step Acc: 1.0 Loss: 0.00234557\n",
      "Epoch 62, CIFAR-10 Batch 4:  Valid Acc: 0.7142 Step Acc: 1.0 Loss: 0.00205383\n",
      "Epoch 62, CIFAR-10 Batch 5:  Valid Acc: 0.713 Step Acc: 1.0 Loss: 0.00242152\n",
      "Epoch 63, CIFAR-10 Batch 1:  Valid Acc: 0.7184 Step Acc: 1.0 Loss: 0.00221034\n",
      "Epoch 63, CIFAR-10 Batch 2:  Valid Acc: 0.7196 Step Acc: 1.0 Loss: 0.00196402\n",
      "Epoch 63, CIFAR-10 Batch 3:  Valid Acc: 0.7154 Step Acc: 1.0 Loss: 0.00187551\n",
      "Epoch 63, CIFAR-10 Batch 4:  Valid Acc: 0.7024 Step Acc: 1.0 Loss: 0.0029952\n",
      "Epoch 63, CIFAR-10 Batch 5:  Valid Acc: 0.7116 Step Acc: 1.0 Loss: 0.00331604\n",
      "Epoch 64, CIFAR-10 Batch 1:  Valid Acc: 0.716 Step Acc: 1.0 Loss: 0.0023834\n",
      "Epoch 64, CIFAR-10 Batch 2:  Valid Acc: 0.7238 Step Acc: 0.998762 Loss: 0.00400583\n",
      "Epoch 64, CIFAR-10 Batch 3:  Valid Acc: 0.7154 Step Acc: 1.0 Loss: 0.00224641\n",
      "Epoch 64, CIFAR-10 Batch 4:  Valid Acc: 0.7198 Step Acc: 1.0 Loss: 0.00122167\n",
      "Epoch 64, CIFAR-10 Batch 5:  Valid Acc: 0.7154 Step Acc: 1.0 Loss: 0.00142476\n",
      "Epoch 65, CIFAR-10 Batch 1:  Valid Acc: 0.717 Step Acc: 1.0 Loss: 0.00211648\n",
      "Epoch 65, CIFAR-10 Batch 2:  Valid Acc: 0.7224 Step Acc: 1.0 Loss: 0.00244659\n",
      "Epoch 65, CIFAR-10 Batch 3:  Valid Acc: 0.715 Step Acc: 1.0 Loss: 0.00200552\n",
      "Epoch 65, CIFAR-10 Batch 4:  Valid Acc: 0.719 Step Acc: 1.0 Loss: 0.00108117\n",
      "Epoch 65, CIFAR-10 Batch 5:  Valid Acc: 0.7164 Step Acc: 1.0 Loss: 0.00184959\n",
      "Epoch 66, CIFAR-10 Batch 1:  Valid Acc: 0.719 Step Acc: 1.0 Loss: 0.00134775\n",
      "Epoch 66, CIFAR-10 Batch 2:  Valid Acc: 0.7172 Step Acc: 1.0 Loss: 0.00238436\n",
      "Epoch 66, CIFAR-10 Batch 3:  Valid Acc: 0.722 Step Acc: 1.0 Loss: 0.00140796\n",
      "Epoch 66, CIFAR-10 Batch 4:  Valid Acc: 0.7204 Step Acc: 1.0 Loss: 0.00113861\n",
      "Epoch 66, CIFAR-10 Batch 5:  Valid Acc: 0.7148 Step Acc: 1.0 Loss: 0.00167957\n",
      "Epoch 67, CIFAR-10 Batch 1:  Valid Acc: 0.717 Step Acc: 1.0 Loss: 0.00156661\n",
      "Epoch 67, CIFAR-10 Batch 2:  Valid Acc: 0.72 Step Acc: 1.0 Loss: 0.00258397\n",
      "Epoch 67, CIFAR-10 Batch 3:  Valid Acc: 0.7208 Step Acc: 1.0 Loss: 0.00162274\n",
      "Epoch 67, CIFAR-10 Batch 4:  Valid Acc: 0.7124 Step Acc: 1.0 Loss: 0.00122606\n",
      "Epoch 67, CIFAR-10 Batch 5:  Valid Acc: 0.7172 Step Acc: 1.0 Loss: 0.00113706\n",
      "Epoch 68, CIFAR-10 Batch 1:  Valid Acc: 0.7164 Step Acc: 1.0 Loss: 0.00123358\n",
      "Epoch 68, CIFAR-10 Batch 2:  Valid Acc: 0.7182 Step Acc: 1.0 Loss: 0.0025569\n",
      "Epoch 68, CIFAR-10 Batch 3:  Valid Acc: 0.7198 Step Acc: 1.0 Loss: 0.00119239\n",
      "Epoch 68, CIFAR-10 Batch 4:  Valid Acc: 0.7154 Step Acc: 1.0 Loss: 0.00112627\n",
      "Epoch 68, CIFAR-10 Batch 5:  Valid Acc: 0.717 Step Acc: 1.0 Loss: 0.00127518\n",
      "Epoch 69, CIFAR-10 Batch 1:  Valid Acc: 0.7176 Step Acc: 1.0 Loss: 0.00149037\n",
      "Epoch 69, CIFAR-10 Batch 2:  Valid Acc: 0.7162 Step Acc: 0.998762 Loss: 0.00294159\n",
      "Epoch 69, CIFAR-10 Batch 3:  Valid Acc: 0.7182 Step Acc: 1.0 Loss: 0.00176204\n",
      "Epoch 69, CIFAR-10 Batch 4:  Valid Acc: 0.7148 Step Acc: 1.0 Loss: 0.000825919\n",
      "Epoch 69, CIFAR-10 Batch 5:  Valid Acc: 0.7194 Step Acc: 1.0 Loss: 0.00111525\n",
      "Epoch 70, CIFAR-10 Batch 1:  Valid Acc: 0.719 Step Acc: 1.0 Loss: 0.00153558\n",
      "Epoch 70, CIFAR-10 Batch 2:  Valid Acc: 0.7202 Step Acc: 1.0 Loss: 0.00187512\n",
      "Epoch 70, CIFAR-10 Batch 3:  Valid Acc: 0.7152 Step Acc: 1.0 Loss: 0.00263432\n",
      "Epoch 70, CIFAR-10 Batch 4:  Valid Acc: 0.7134 Step Acc: 1.0 Loss: 0.00175487\n",
      "Epoch 70, CIFAR-10 Batch 5:  Valid Acc: 0.7202 Step Acc: 1.0 Loss: 0.00108781\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.7116031587123871\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20d92bfc390>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
